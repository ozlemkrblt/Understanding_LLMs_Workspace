{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozlemkrblt/Understanding_LLMs_Workspace/blob/main/understanding-llms/tutorials/01-introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3S_GSA0K5Hn"
      },
      "source": [
        "Sheet 1.1: Practical set-up & Training data\n",
        "========================\n",
        "\n",
        "**Author**: Polina Tsvilodub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyeHlJXjK5Ht"
      },
      "source": [
        "\n",
        "This page contains materials for the first tutorial session.\n",
        "\n",
        "The learning goals for the first tutorial are:\n",
        "\n",
        "* preparing the Python requirements for practical exercises in the upcoming tutorials,\n",
        "* test-running a few lines of code,\n",
        "* familiarization with a few coding best practices,\n",
        "* understanding key processing steps and terms of the first building block for training any language model -- the training data.\n",
        "\n",
        "**Please try to complete the first block of this tutorial sheet (i.e., installation of requirements) AHEAD of the tutorial session**, ideally, while you have a stable internet connection. This way we can try to solve any problems that might have come up with the installation during the tutorial on Friday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWr2fCVAK5Hu"
      },
      "source": [
        "## Installing requirements\n",
        "\n",
        "Throughout the semester, we will use Python, PyTorch and various packages for practical work. Both the in-tutorial exercise sheets and homework will require you to execute Python code yourself.\n",
        "Please follow the steps below to set up the requirements (i.e., most packages required for completing exercises) that we will use in the course. We will most likely install more packages as we go during the semester, though.\n",
        "\n",
        "You can do so either on your own machine, or by using [Google Colab](https://colab.research.google.com/). You can easily access the latter option by pressing the Colab icon at the top of the webook's page. Depending on your choice, please follow the respective requirement installation steps below.\n",
        "\n",
        "Please note that working with language models is quite compute-intensive. That is, their weight require a lot of disk space, and most importantly, a relatively performant GPU, both for inference and for training. For most purposes of this course, using Colab is the recommended option, unless you have a performant GPU on your laptop. However, there are two additional resources we will take advantage of: [bwJupyter](https://www.bwjupyter.de/), a server provided by the state of Baden-Württemberg, and the API provided by NVIDIA. More on both services below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYatmDXuK5Hu"
      },
      "source": [
        "### Colab\n",
        "\n",
        "The advantage of using Colab is that you don't need to install software on your own machine; i.e., it is a safer option if you are not very comfortable with using Python on your own machine. Colab is a  platform provided by Google for free, and it also provides limited access to GPU computation (which will be useful for working with language models). Using it only requires a Google account.\n",
        "\n",
        "For using a GPU on Colab, before executing your code, navigate to Runtime > Change runtime type > GPU > Save. Please note that the provided Colab computational resources are free, so please be mindful when using them. Further, Colab monitors GPU usage, so if it is used a lot very frequently, the user might not be able to access GPU run times for a while.\n",
        "\n",
        "Colab already provides Python as well as a number of basic packages. If you choose to use it, you will only need to install the more specific packages. Note that you will have to so *every time* you open a new Colab runtime. To test that you can access requirements for the class, please open this notebook in Colab (see above), uncomment and run the following line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5B85MxX2K5Hv",
        "outputId": "c286e860-6a87-4c1b-83d1-61ca94c37a09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langchain_nvidia_ai_endpoints==0.3.9\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-dotenv==1.1.0\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index\n",
            "  Downloading llama_index-0.12.34-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (0.3.56)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.39)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Collecting tensordict<0.9.0,>=0.8.1 (from torchrl)\n",
            "  Downloading tensordict-0.8.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl.metadata (438 bytes)\n",
            "Collecting llama-index-cli<0.5,>=0.4.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.4.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.13,>=0.12.34 (from llama-index)\n",
            "  Downloading llama_index_core-0.12.34.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting llama-index-llms-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
            "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
            "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.38.11-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.76.2)\n",
            "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading banks-2.1.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.2.18)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (11.2.1)\n",
            "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.34->llama-index) (1.17.2)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.20-py3-none-any.whl.metadata (914 bytes)\n",
            "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_parse-0.6.21-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.1->torchrl) (8.7.0)\n",
            "Collecting botocore<1.39.0,>=1.38.11 (from boto3->bertviz)\n",
            "  Downloading botocore-1.38.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index) (4.3.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (3.0.0)\n",
            "Collecting llama-cloud-services>=0.6.21 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud_services-0.6.21-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict<0.9.0,>=0.8.1->torchrl) (3.21.0)\n",
            "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.19-py3-none-any.whl.metadata (902 bytes)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.34->llama-index)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading langchain_nvidia_ai_endpoints-0.3.9-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchrl-0.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.12.34-py3-none-any.whl (7.0 kB)\n",
            "Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading llama_index_agent_openai-0.4.7-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.12.34.post1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\n",
            "Downloading llama_index_llms_openai-0.3.38-py3-none-any.whl (23 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensordict-0.8.2-cp311-cp311-manylinux_2_28_x86_64.whl (414 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.38.11-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading botocore-1.38.11-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading llama_parse-0.6.21-py3-none-any.whl (4.9 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading llama_cloud_services-0.6.21-py3-none-any.whl (37 kB)\n",
            "Downloading llama_cloud-0.1.19-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.6/263.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=fd7dc26e0ef81b5a6d179b94d7bc7b7eebb19c0b3e87c8ecac8ea7e2b8d918b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, xxhash, python-dotenv, pypdf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, jmespath, httpx-sse, fsspec, dill, colorama, wikipedia, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, griffe, botocore, s3transfer, pydantic-settings, nvidia-cusolver-cu12, llama-cloud, dataclasses-json, banks, llama-index-core, datasets, boto3, tensordict, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langchain_nvidia_ai_endpoints, bertviz, torchrl, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, langchain-community, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed banks-2.1.2 bertviz-1.4.0 boto3-1.38.11 botocore-1.38.11 colorama-0.4.6 dataclasses-json-0.6.7 datasets-3.6.0 dill-0.3.8 dirtyjson-1.0.8 filetype-1.2.0 fsspec-2025.3.0 griffe-1.7.3 httpx-sse-0.4.0 jmespath-1.0.1 langchain-community-0.3.23 langchain_nvidia_ai_endpoints-0.3.9 llama-cloud-0.1.19 llama-cloud-services-0.6.21 llama-index-0.12.34 llama-index-agent-openai-0.4.7 llama-index-cli-0.4.1 llama-index-core-0.12.34.post1 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-openai-0.3.38 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.21 marshmallow-3.26.1 multiprocess-0.70.16 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.9.1 pypdf-5.4.0 python-dotenv-1.1.0 s3transfer-0.12.0 striprtf-0.0.26 tensordict-0.8.2 tiktoken-0.9.0 torchrl-0.8.0 typing-inspect-0.9.0 wikipedia-1.4.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        " !pip install torch transformers datasets langchain-community langchain_nvidia_ai_endpoints==0.3.9 python-dotenv==1.1.0 torchrl llama-index bertviz wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyexPfesK5Hx"
      },
      "source": [
        "Alternatively, if you want, you can also download the requirements file [here](https://github.com/CogSciPrag/Understanding-LLMs-course/tree/main/understanding-llms/tutorials/files/requirements.txt) and install from it by running `!pip install -r requirements.txt`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc4QGMx5K5Hx"
      },
      "source": [
        "### Local installation\n",
        "\n",
        "Using your computer for local execution of all practical exercises might be a more advanced option. If you do so, we strongly encourage you to create an environment (e.g., with Conda) before installing any packages. Furthermore, ideally, check if you have a GPU suitable for deep learning because using a GPU will significantly speed up the work with language models. You can do so by checking your computer specs and finding out whether your GPU works with CUDA, MPS or ROCm. If you don't have a suitable GPU, you can use Colab for tasks that require GPU access. Finally, please note that we will download some pretrained models and some datasets which will occupy some of your local storage.\n",
        "\n",
        "If you choose to use your own machine, please do the following steps:\n",
        "* install Python >= 3.10\n",
        "* create an environment (optional but recommended)\n",
        "* download the requirements file [here](https://github.com/CogSciPrag/Understanding-LLMs-course/tree/main/understanding-llms/tutorials/files/requirements.txt)\n",
        "* if you have a deep learning supporting GPU:\n",
        "  * please check [here](https://pytorch.org/get-started/locally/) which PyTorch version you need in order to use the GPU\n",
        "  * please modify the first line of the requirements file to reflect the PyTorch version suitable for your machine (if needed)\n",
        "  * please install the requirements from the requirements file (e.g., run: `pip install -r requirements.txt` once pip is available in your environment; adjust path to file if needed)\n",
        "* if you do NOT have a deep learning supporting GPU:\n",
        "  * please install the requirements from the requirements file (e.g., run: `pip install -r requirements.txt` once pip is available in your environment; adjust path to file if needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geMslxzmK5Hy"
      },
      "source": [
        "### bwJupyter\n",
        "\n",
        "This is a compute service provided by the state of Baden-Württemberg, specifically for educational purposes. It hosts a Jupyter Notebook server and also provides access to GPUs, as documented [here](https://www.bwjupyter.de/english/65.php). However, the available resources are very limited: only 2GB drive space and 8GB RAM per user. Although the available GPUs are large, there seems to be a cap of 6GB vRAM (GPU memory) per user. Therefore, we might only make use of this service for selected purposes.\n",
        "\n",
        "Nevertheless, please try accessing the server with your **uni email** [here](https://hub.bwjupyter.de/hub/login?next=%2Fhub%2F). We will need it later in the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbA-omgeK5Hy"
      },
      "source": [
        "### NVIDIA API\n",
        "\n",
        "NVIDIA hosts an API that provides to many state-of-the-art LLMs. This means, NVIDIA servers host these LLMs, and we can retrieve predictions from these models (i.e., *run inference* on them) by submitting an input to the API, without having to download the weights and run the entire LLM ourselves. The API can be accessed by signing up for an account. However, there are also limitations when using an API; for instance, we cannot access the internal model representations or conditional probabilities, or train the models. Therefore, we will make use of the API in later sessions which rather rely on prompting.\n",
        "Detailed instructions on how to sign up and use the API can be found [here](https://maxschmaltz.github.io//Course-LLM-based-Assistants/infos/llm_inference_guide/README.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ww0hpqK5Hz"
      },
      "source": [
        "## Verifying requirement installation\n",
        "\n",
        "Please run the following code cells to make sure that the key requirements were installed successfully. If errors occur and you cannot solve them ahead of the tutorial, please don't be shy and let us know in the first tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UmRAR8cLK5Hz"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from langchain.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t1n2NHcvK5Hz",
        "outputId": "08911490-9c36-4865-a318-92486d915bac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# check available computation device\n",
        "# if you have a local GPU or if you are using a GPU on Colab, the following code should return \"CUDA\"\n",
        "# if you are on Mac and have an > M1 chip, the following code should return \"MPS\"\n",
        "# otherwise, it should return \"CPU\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Device: {device}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(f\"Device: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_MX_jHuRK5Hz",
        "outputId": "a60f53bc-7029-43e1-83bb-6833445b21e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0055, 0.9467, 0.0623],\n",
            "        [0.0511, 0.9671, 0.8434],\n",
            "        [0.0631, 0.9221, 0.9521],\n",
            "        [0.6457, 0.1124, 0.6728],\n",
            "        [0.6472, 0.5355, 0.6931]])\n",
            "Shape of tensor x: torch.Size([5, 3])\n",
            "Device of tensor x: cpu\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.0055, 0.9467, 0.0623],\n",
            "        [0.0511, 0.9671, 0.8434],\n",
            "        [0.0631, 0.9221, 0.9521],\n",
            "        [0.6457, 0.1124, 0.6728],\n",
            "        [0.6472, 0.5355, 0.6931]])\n",
            "tensor([[1.0144, 1.0144, 1.0144, 1.0144, 1.0144],\n",
            "        [1.8616, 1.8616, 1.8616, 1.8616, 1.8616],\n",
            "        [1.9373, 1.9373, 1.9373, 1.9373, 1.9373],\n",
            "        [1.4309, 1.4309, 1.4309, 1.4309, 1.4309],\n",
            "        [1.8758, 1.8758, 1.8758, 1.8758, 1.8758]])\n",
            "tensor([[1.4127, 1.4127, 1.4127],\n",
            "        [3.4837, 3.4837, 3.4837],\n",
            "        [3.2237, 3.2237, 3.2237]])\n"
          ]
        }
      ],
      "source": [
        "# test PyTorch\n",
        "\n",
        "# randomly initialize a tensor of shape (5, 3)\n",
        "x = torch.rand(5, 3).to(device)\n",
        "print(x)\n",
        "print(\"Shape of tensor x:\", x.shape)\n",
        "print(\"Device of tensor x:\", x.device)\n",
        "\n",
        "# initialize a tensor of shape (5, 3) with ones\n",
        "y = torch.ones(5, 3).to(device)\n",
        "print(y)\n",
        "\n",
        "# multiply x and y in a pointwise manner\n",
        "z = x * y\n",
        "print(z)\n",
        "\n",
        "# note that to do a matrix multiplication between x and y, we need to transpose\n",
        "# either matrix x or y because the inner dimensions must match\n",
        "z1 = x @ y.T\n",
        "print(z1)\n",
        "\n",
        "# or:\n",
        "z2 = x.T @ y\n",
        "print(z2)\n",
        "# and note that the result of z1 and z2 are not the same and have different shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6JXZ4sx9K5H0",
        "outputId": "aec5cb98-dfab-43d2-8764-8decc5c4a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Attention Is All You Need\\nSummary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, and a main contributor to the AI boom, as the transformer approach has become the main architecture of a wide variety of AI, such as large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique\\'s potential for other tasks like question answering and what is now known as multimodal Generative AI.\\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Jakob Uszkoreit, one of the paper\\'s authors, liked the sound of that word.\\nAn early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers franchise. The team was named Team Transformer.\\nSome early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\\nAs of 2025, the paper has been cited more than 173,000 times, placing it among top ten most-cited papers of the 21st century.\\n\\nPage: All You Need Is Kill\\nSummary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\\nA manga adaptation, written by Ryosuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha\\'s Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A live-action film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title. An anime film adaptation produced by Studio 4°C has been announced.\\nThe novel was Sakurazaka\\'s breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and Chōhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\\n\\nPage: Transformer (deep learning architecture)\\nSummary: The transformer is a deep learning architecture that was developed by researchers at Google and is based on the multi-head attention mechanism, which was proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be diminished.\\nTransformers have the advantage of having no recurrent units, therefor'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# testing LangChain\n",
        "\n",
        "# run a Wikipedia query, searching for the article \"Attention is all you need\"\n",
        "# NB: requires an internet connection\n",
        "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "wikipedia.run(\"Attention is all you need\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O_FIoyyMK5H0",
        "outputId": "af61f7f2-7b41-4e17-fd12-9f1d015b3247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "7666888c43134bea8bfa0645548a76aa",
            "e2bc895977ff40ea8bf2fd281813f8b2",
            "4265c5e9a93c4f10a2c9c8a8729e5ba1",
            "31cb75425f1f406c866bf81e071a6655",
            "5e646bf95ba54d2cbde441bce87bb6ad",
            "32da1951624244b388c7d6615f1df66f",
            "30107a0b7f394f83a122bcb58c09247a",
            "51f6985af7014fa2b07d67459fca8a6f",
            "f66d2f12f5214959b6908ba96392669b",
            "e9ffd9492b2e47bf9ebdd53980e71a71",
            "9278d869d1b14fb2ab7e8128456cca9d",
            "40b658ca1dff49f0a5656440deb3194a",
            "7d78fa15157141cc8fe01a8f5cac6cd8",
            "57e5ebb2fb6448509a1c18fb01d470a0",
            "8709eb69d9224b96ad08608de685bdb1",
            "08196a6416ff401d96b3c60da7fc49ef",
            "c50f4e45b8434c27a2a9a9903beace9b",
            "84c1a96b71d742d8a6fc3a4985658f01",
            "f130482693c54e50941b9155558babba",
            "80f55a7351034fb09fec090feb0346d4",
            "8654c40db7c242aaa0af42611fe75e4e",
            "9d3c2efefd154996880a3f9af5f1669d",
            "8c75b8332ad94ac18f2de1a771e3d8af",
            "dfab0908cb9a46b0801dae50a69cfc61",
            "ac2856bd1aca448fad2915fa9ef3e551",
            "77c14840d13c46f8a1c5bf2ff7268669",
            "df47c85dea044322a76233feb810e307",
            "4af9976a979a4bda86317cc84ba99829",
            "ef1cad26dd484612b81e4cdfbae81295",
            "b198512be22b4dfbbc764369734bcaad",
            "b3edfd1b5c0549c7b7875b7024692094",
            "8a626dc696914b37a43cec441ca5c2c9",
            "e5d5335040474592a6d67f923ea598ff",
            "3dc3347c08374ab296db528aeaa8f408",
            "c903f41336a44c6d9023b7402348fe95",
            "026a8860febf45a4961fbf9ebd29501b",
            "bfe928d198b64ed586ad4dfb404a16be",
            "b7ebe158854748f596d79b4b8f00fc6a",
            "daae172bd1d1405a9b95bf7411bff8e9",
            "815014d33fcb42a5a8b0fc23702d0a9c",
            "776fdbac9e9a4bec8803c0def13ebb12",
            "8ae548da59f147b486ce5c8847de1606",
            "fa12da8cff4643eab586fe2226428001",
            "73e48459733f487394fbf71e5d0e4b09",
            "a67856e1dca543b399e6829497fb6d64",
            "a57fe4e006774164b09d0931d830c1d4",
            "a5dc83748a3341fbbb9f6a447c3287f6",
            "16f1b4cdf42a4ed9a9805cf88a668625",
            "ba7f5dc15df944449cf52f2506297d9a",
            "72fa977b961b4376b8ea2a135fbd3940",
            "34e50aaaa8f449608c08545ff78ddea1",
            "3179ccc270ce47d1842b5cc444ce3640",
            "fcd1af1b65894394ba91574b3a8673c4",
            "b9f8c5b9b47747a59aad6dd95dced42b",
            "6788e219db324ea9bea3d3c4a61cd663"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7666888c43134bea8bfa0645548a76aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40b658ca1dff49f0a5656440deb3194a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c75b8332ad94ac18f2de1a771e3d8af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dc3347c08374ab296db528aeaa8f408"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a67856e1dca543b399e6829497fb6d64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: {'input_ids': tensor([[8086, 1463,  318,  477,  345,  761]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "# testing the package transformers which provides pre-trained language models\n",
        "# and excellent infrastructure around them\n",
        "\n",
        "# download (if not available yet) and load GPT-2 tokenizer\n",
        "tokenizer_gpt2 = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "text = \"Attention is all you need\"\n",
        "# tokenize the text (i.e., convert the string into a tensor of token IDs)\n",
        "input_ids = tokenizer_gpt2(\n",
        "    text,\n",
        "    return_tensors=\"pt\",\n",
        ").to(device)\n",
        "\n",
        "print(\"Input IDs:\", input_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnCPUAJDK5H0"
      },
      "source": [
        "## Best practices for writing code\n",
        "\n",
        "There is a lot of debate around best practices for writing, documenting and formatting Python code and their actual implementation in daily practice, and many people have different personal preferences. We are not committing to a particular side in this debate, but we do care about a few general aspects:\n",
        "* working with clean code\n",
        "* working with understandable code (i.e., commented, with understandable variable names etc)\n",
        "* producing well-documented projects (e.g., supplied with relevant READMEs etc). Think: your work should be structured such that you could look at it in a year and be able to immediately know what you did, how and why.\n",
        "\n",
        "There are a few de facto standard *formatting* practices that help to keep Python code crisp and clean. Please take a look at these and adhere to these as much as you can (as so will we):\n",
        "* [PEP8](https://pep8.org/): style guide for Python code defining e.g., variable naming conventions, how many spaces to use for indentation, how long single lines should be etc.\n",
        "  * Here is an overview [video](https://www.youtube.com/watch?v=D4_s3q038I0) of some of the PEP8 conventions\n",
        "  * There is handy software that reformats your code for you according to some of these conventions. Such software is often seamlessly integrated in IDEs. This includes for instance *Black* or *Ruff* Python formatters. They can be installed as extensions in, e.g., Visual Studio Code.\n",
        "* *docstrings* are comments (strings) that document a specific code object and always directly follow the definition of the object (e.g., directly after `def fct(...)`). They specify the functionality, inputs, outputs and their types. Again, there are slightly different formatting styles for docstrings; please try to be consistent about your formatting.\n",
        "  * One example style of docstrings is [*numpydoc*](https://numpydoc.readthedocs.io/en/latest/format.html#docstring-standard); you might see that the provided code might often use such docstrings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YlB74hhyK5H0"
      },
      "outputs": [],
      "source": [
        "# example: bad formatting\n",
        "def add(a,b):\n",
        "    return a+b\n",
        "\n",
        "# example: better formatting\n",
        "def add(a, b):\n",
        "    return a + b\n",
        "\n",
        "# example: bad docstring\n",
        "\n",
        "def add(a, b):\n",
        "    \"\"\"a+b\"\"\"\n",
        "    return a + b\n",
        "\n",
        "# example: better docstring\n",
        "def add(a, b):\n",
        "    \"\"\"\n",
        "    Add two numbers.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    a: int\n",
        "        First number.\n",
        "    b: int\n",
        "        Second number.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int: Sum of a and b.\n",
        "    \"\"\"\n",
        "    return a + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rowa7C3BK5H1"
      },
      "source": [
        "There are also some hints regarding structuring larger projects and e.g. GitHub repositories (just fyi):\n",
        "\n",
        "* [project structure](https://djnavarro.net/slides-project-structure/#1)\n",
        "* [writing good READMEs](https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/)\n",
        "* [tidy collaboration and git](https://vimeo.com/412835411)\n",
        "\n",
        "These best practices will be useful to you beyond this class and possibly even beyond your studies when collaborating on other coding projects within teams or even by yourself. We do our best to stick to these guidelines ourselves and kindly urge you to do the same when submitting assignments and possibly projects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPBrhx3gK5H1"
      },
      "source": [
        "## Understanding training data\n",
        "\n",
        "One of the critical building blocks of any language model (be it an n-gram model or GPT-4) is the **training data**. The contents of the training data determine, for instance, which tokens (e.g., words) the model \"sees\" during training, how often each of them occurs, which language the model learns, but also which potential *biases* the model might inherit (more on this in lecture 9).\n",
        "\n",
        "The goals of this part of the sheet are:\n",
        "* introduce core terms and concepts that we might be using throughout the class, and that are often used in NLP papers\n",
        "* understand core data processing steps used before training LMs\n",
        "* try hands-on loading a dataset and performing basic preprocessing steps\n",
        "\n",
        "Tasks:\n",
        "* read the sections below, try to understand each concept and ask yourself whether you have already heard it, and if so, in which context\n",
        "* complete the exercises\n",
        "* complete the coding exercises where you can load and process a dataset yourself.\n",
        "\n",
        "### Core concepts\n",
        "\n",
        "* **(training) data / dataset** (in the context of LMs): a collection of text data which is used as input to the LM in order to optimize its parameters, so that, ideally, the model learns to perform well on its target task; that is, to predict fluent text. Anything from a single sentence to a book can be considered data; but since learning statistics of natural language is very difficult, usually very large collections of texts (i.e., very large datasets) are used to train LMs. Generalization to other machine learning models: the type of input data might be different (e.g., images and labels for image classification models) but the purpose is the same. Data and dataset are mostly used interchangeably.\n",
        "  * **corpus** [ling.]: \"A corpus is a collection of pieces of language text in electronic form, selected according to external criteria to represent, as far as possible, a language or language variety as a source of data for linguistic research.\" [source](https://user.phil.hhu.de/~bontcheva/SS10CTCL/CTCL-IntroNotes.pdf) For the purposes of NLP, the term corpus is often used interchangeably with the term dataset, especially when referring to collections of literary texts (e.g., the Books corpus) or when sourced from corpora created in linguistics.\n",
        "    * well-known linguistic corpora are, e.g.: the [Brown corpus](http://icame.uib.no/brown/bcm.html), the British National Corpus [BNC](http://www.natcorp.ox.ac.uk/).\n",
        "  * **test / validation data** (general ML concept): the full dataset is sually split into the *training data* (used to optimize the model), and the held-out *validation data* and *test data* (called dataset splits). Validation data is often used to optimize aspects of the model architecture (so-called hyperparameters like optimizer, drop out rate etc). This split is sometimes ommited if no hyperparameter tuning is done. Test data is then used to assess the model's performance on *unseen* data. That is, it is used to approximately answer the question: How well will my trained model perform on completely new inputs? In the context of LMs, all dataset splits are texts.\n",
        "* **cleaning & preprocessing**: this is the step when \"raw\" data (e.g., from the web) is processed so as to massage the data into a format that is optimal for the NLP task which we want to accomplish. This can include, for instance, removing markup tags, lower-casing data, splitting it into single sentences etc.\n",
        "* **annotation**: this step refers to enriching \"raw\" data with additional information like judgements about the quality of data, \"gold standard\" demonstrations of a task (e.g., gold standard answer to a question) etc, usually provided by humans. This is done generate high-quality training datasets which cannot be obtained otherwise.\n",
        "  * most prominently, human annotation is often used in the process of fine-tuning LLMs with RLHF (more on this in lecture 5).\n",
        "* **token**: minimal unit of text which is mapped onto a numerical representation to be readable for the LM. Different types of tokens have been used: single words, single characters, and recently mostly sub-word parts (and most most recently some experiments with tokens that are large multi-word chunks). Note that unique minimal units are assigned different tokens; whenever such a unit occurs in a particular context, the same numerical representation (i.e., token ID) is assigned to that unit. Therefore, the notion of a token in NLP is not completely equivalent to the notion in lingusitics (and there are no types in NLP as opposed to linguistics).  \n",
        "  * tokenization is the process of converting a string to a list or tensor of tokens.\n",
        "  * part of tokenization for training transformers is also creating *attention masks* which \"mask\" certain tokens for the model (i.e., hide it from the model during training). This is done to train models to predict next words based only on preceding context.\n",
        "  * tokenization will be discussed in more detail in the session of week 3.\n",
        "* **vocabulary**: the set of unique tokens used by a particular LM-tookenizer pair. For example, in case of the Llama-2 model, the vocabulary consists of ~32 000 tokens.\n",
        "* **embedding**: a vector representation of a single token (e.g., word2vec). These vector representations are learned in a way optimizing the next token prediction task and, intuitively, can be understood as approximating (some aspects of) the meaning of a word.\n",
        "* **batch**: a set of input samples (i.e., texts) that is passed through the LM during training simultaneously, in parallel, during one training step, before updating the internal model parameters. The **batch size** refers to the number of input samples in the set. The batch size is a common hyperparameter of the LM architectures and might have a significant effect on set-up requirements (a large batch size requires a lot of memory) and the model performance (because model parameters are updated based on the training signal from the entire batch).\n",
        "* **epoch**: an interation over the entire training dataset. Often a model is trained for several epochs, i.e., training iterates over the training set several times.\n",
        "\n",
        "We will likely extend this list and learn about more important aspects as we go on with the class, but this should already equip you with a good foundation for understanding the parts of the LM literature related to data.\n",
        "\n",
        "### Main training data processing steps\n",
        "\n",
        "Before beginning to train the LM, the following steps are commonly completed:\n",
        "\n",
        "1. acquiring the training data: this step involves downloading or collecting the data of your choice onto the machine which will be used for training. Nowadays many datasets for various tasks can be downloaded from [HuggingFace](https://huggingface.co/datasets) or are made available in GitHub repositories.\n",
        "2. exploring and understanding the dataset: it is important to understand what kinds of texts, from which sources, on which topics, with what sentence length, ... the dataset contains. This is crucial because the model will pick up on features of the dataset in a way that might be difficult to fully anticipate (which is good if the features are, e.g., gramamticality of sentences, but bad if it is toxic language).\n",
        "3. creating the desired combination: nowadays training datasets might consist of a mix of different smaller datasets. See the exercise below for more details.\n",
        "4. cleaning: this step involves filtering out or converting non-machine readable or undesired characters, often lower-casing, removal of punctuation or digits or so-called stop-words (very common words like \"a\", \"and\"). However, the last three steps are not very common any more for state-of-the-art LLM training.\n",
        "   * Specifically, the last cleaning steps have been introduced for tasks like, e.g., sentiment classification. Arguably, stopwords and punctuation etc probably don't contribute much task-relevant information, but might rather introduce encoding difficulties. On the other hand, for natural language generation, punctuation, all words as well as other symbols like emojis carry valuable information. Therefore, such preprocessing is not common for LM training.\n",
        "5. splitting the dataset into train, validation, test splits\n",
        "6. prepairing the training split: training texts are often shuffled and sometimes split into shorter texts. Specifically, splitting is required if the length of a text exceeds the maximal *context window size* of the transformer model (i.e., the maximal number of tokens a model can process). In this case, texts are often split into shorter slightly overlapping chunks.\n",
        "7. tokenizing: converting the single texts into lists of tokens, i.e., into lists of numerical IDs. More on tokenization in the session of week 3.\n",
        "8. batching: to speed up training, the model is often fed multiple texts at the same time (i.e., at each training step). To create these batches, often additional steps are needed to ensure that several tokenized texts (i.e., several lists with token IDs) can be represented as one input tensor. These steps are either restricting texts to a maximal common length (and cutting off the rest) or *padding* all the texts to the same length. More on this in the tokenization session.\n",
        "\n",
        "[This article](https://www.geeksforgeeks.org/natural-language-processing-nlp-pipeline/) provides a great and more detailed overview of the steps 1-4 and provides insights into traditional approaches (e.g., feature engineering) which are more common for task-specific models than for foundation language models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz948LQCK5H1"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.1.: Massaging a Twitter dataset</span></strong>\n",
        ">\n",
        "> Below are a few code blocks for implementing some data processing steps on an example dataset of [tweets about financial news](https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment), downloaded from HuggingFace. We will use the `datasets` [package](https://huggingface.co/docs/datasets/en/tutorial) to work with the dataset. Originally, the dataset is intended for sentiment classification, but we will just use the tweets from the column \"text\".\n",
        ">\n",
        "> 1. Please go through the code and complete it in slots which say \"#### YOUR CODE HERE\". Refer to the comments and hints for instructions about what the code is supposed to do. Make sure to try to understand every line!\n",
        ">\n",
        "> 2. What is prominent about the dataset? Are the processing steps adequate if you wanted to train a Twitter bot which could write tweets on this data? Specifically, do you think the resulting cleaned sentences are sensible, good training examples to learn to generate text, and, more specifically, tweets?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b1zXzoP7K5H1",
        "outputId": "8f872dfb-e8f5-425c-bcb6-90e7e8128b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721,
          "referenced_widgets": [
            "7b07ffdb8a5842c3970b367de51394b0",
            "7857bc4b5d5847b990f1f0ef244dc5cc",
            "fa2c2116f1154285aaf132c4dcbfcbe9",
            "d5daeabf00264fb38ba641e786737ed9",
            "ce33f664601f432f9977e962cf22663b",
            "9305fbe05ea84180a20ed2a8636a1b69",
            "e383bc0443bf4c4a840fd67247b844c3",
            "f01778ec224b446388e8f671eeafefbb",
            "ecfcc538cb4446ba98c7ca706eeb3304",
            "f5f1025a8f924e79b9f73a1e27a9b0c1",
            "adef70b47c37472ab165bc9dc6ffc196",
            "6a8da515c37547298b8dd4a87fb9149a",
            "51f3067fac6842839520f75477f5d8e7",
            "b6b60c9459b7424daf77ced6dd117998",
            "e53b0e0f2b344b2c9a6e43ca5b91c7fe",
            "adb4ed6443454e419f8d7087525dd2be",
            "fe4502e9ed0943b494c22069745a87d5",
            "278b4e81e5374d96a243e4452f70df56",
            "8d928dada3a94bbc9612482f2adf4768",
            "5952ed15b4c3458b823a6d799d746f9d",
            "281e3c86291141899226b472fa58a44b",
            "644b7993430748a599f9f6aecafe5e13",
            "f9ffc5eb84434334859076e6de10dd50",
            "4f04bbf6720e4ff490e275aa8ffbe355",
            "28b509d01c834cf8b9c4794ad1edb165",
            "04ff99cd8ade4149a67e09d073f27467",
            "a950676dff9145d7adce329e06df2a08",
            "87c82060f43f444aa92f94245cca7f54",
            "c389a688cedf4b019e666e2be21031cb",
            "6ef2532662d44413a134518c0201d230",
            "48073af66ca24fd19f41c92a607782b8",
            "e0b5b9edec6c48369c63c21b7f8581b7",
            "d81cdf307df949a8b7a2493fd15b906f",
            "9f288755aa8d4bf1b5cbd247613e316e",
            "07ce3276ba2c4f8db6438daa4c441a7e",
            "e1fad3a6618d4de0972d45f8313fa632",
            "9ab1626b086744188b09c8c63dbe924b",
            "265a5756f14440719c97fe1eba9c112a",
            "8f06891ddfd24e52bb068bd6ae9789b9",
            "c6b5ea88a13f40b980d4c6d0e368cd42",
            "47a8b4ec1868468e8a7488e8d5386a6d",
            "eaa0a9fd47aa4a3d9c3c93c7d698b68f",
            "2c06e038543743bc989c1432f6763222",
            "010de7e378b94a3c8a8426d925c27607",
            "dd03d589fe054691b931545da8b6598f",
            "83f3e3d8d24e4591889002574017e9d3",
            "45363e5f7dc649ad866aca79b8e39cde",
            "a3b830d4c3b24f1db7bc83f5a2842d14",
            "dbd36a9d1b384d2f9be353276d80c519",
            "568b534edb694b72b22c3156185d8509",
            "f06c1d082a3c42faa17f8322db0ade89",
            "555d5512c1da4e4aaaf2eda7e9dff9d6",
            "536b3fbd6c484cc887693bebbe86155d",
            "a072ddb7713142448db820c07ac08c10",
            "c6fca28eff4d469c8c2922b813abca93"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b07ffdb8a5842c3970b367de51394b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sent_train.csv:   0%|          | 0.00/859k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a8da515c37547298b8dd4a87fb9149a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sent_valid.csv:   0%|          | 0.00/217k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9ffc5eb84434334859076e6de10dd50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9543 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f288755aa8d4bf1b5cbd247613e316e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd03d589fe054691b931545da8b6598f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT', '$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3', '$CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb', '$ESS: BTIG Research cuts to Neutral https://t.co/MCyfTsXc2N', '$FNKO - Funko slides after Piper Jaffray PT cut https://t.co/z37IJmCQzB'], 'label': [0, 0, 0, 0, 0]}\n",
            "['text', 'label']\n",
            "Dataset size: (9543, 2)\n",
            "Average tweet length: 12.17835062349366\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATTxJREFUeJzt3Xl4TGf/P/D3TNZJZBGRDYkgiCWxFSkiCEG0tj4oadHgaUqVtKpaS+xFaUot3R6xL10sVVQssVetUUSEhlCSdKgsEpFk7t8fvjm/juyTSSY5eb+ua6527nPfcz7nzhFvZ86iEEIIEBEREcmU0tAFEBEREZUnhh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIiIpI1hh0iIiKSNYYdIiIikjWGHSIdhIWFQaFQVMi6/Pz84OfnJ72PioqCQqHADz/8UCHrHzVqFOrXr18h69JVeno6xowZAycnJygUCkyaNMnQJVEJ1a9fH/369TN0GSRzDDtU7UVEREChUEgvc3NzuLi4ICAgAMuXL0daWppe1nP//n2EhYXh0qVLevk8farMtZXEggULEBERgZCQEGzYsAFvvPFGvj55AbW417+DpaFcu3YNYWFhuH37don6522bWq0u38J0VNrtIdI3Y0MXQFRZzJkzB+7u7sjOzkZiYiKioqIwadIkLFu2DLt374aXl5fUd/r06fjoo49K9fn379/H7NmzUb9+fbRq1arE4w4cOFCq9eiiqNq++eYbaDSacq+hLA4fPoyOHTti1qxZhfYZNGgQGjVqJL1PT09HSEgIBg4ciEGDBkntjo6O5VprSVy7dg2zZ8+Gn59fpT+qVhJy2x6qehh2iP5Pnz590K5dO+n9tGnTcPjwYfTr1w+vvvoqYmJioFKpAADGxsYwNi7fPz4ZGRmwsLCAqalpua6nOCYmJgZdf0kkJyejWbNmRfbx8vLSCqxqtRohISHw8vJCUFBQeZdIRAbEr7GIitC9e3fMmDEDd+7cwcaNG6X2gs7ZiYyMROfOnWFra4saNWqgSZMm+PjjjwE8P8/mpZdeAgCMHj1a+sokIiICwPPzclq0aIHz58/D19cXFhYW0tgXz9nJk5ubi48//hhOTk6wtLTEq6++irt372r1qV+/PkaNGpVv7L8/s7jaCjpn58mTJ3j//fdRr149mJmZoUmTJvjss88ghNDqp1AoMGHCBOzcuRMtWrSAmZkZmjdvjv379xc84S9ITk5GcHAwHB0dYW5uDm9vb6xbt05annf+Unx8PH755Repdl2+Lrl8+TIUCgV2794ttZ0/fx4KhQJt2rTR6tunTx906NBBq23fvn3o0qULLC0tYWVlhcDAQFy9ejXfeq5fv47XXnsNdnZ2MDc3R7t27bTWGRERgf/85z8AgG7duknbFBUVVeptKu2689avUChw8uRJhIaGonbt2rC0tMTAgQPx999/a/XVaDQICwuDi4sLLCws0K1bN1y7dk1rvyvp9pw4cQLt27eHubk5GjRogPXr12stz87OxuzZs+Hh4QFzc3PUqlULnTt3RmRkZJnnheSPYYeoGHnnfxT1ddLVq1fRr18/ZGVlYc6cOVi6dCleffVVnDx5EgDg6emJOXPmAADGjRuHDRs2YMOGDfD19ZU+4+HDh+jTpw9atWqF8PBwdOvWrci65s+fj19++QVTp07FxIkTERkZCX9/f2RmZpZq+0pS278JIfDqq6/i888/R+/evbFs2TI0adIEU6ZMQWhoaL7+J06cwDvvvINhw4Zh8eLFePr0KQYPHoyHDx8WWVdmZib8/PywYcMGjBgxAkuWLIGNjQ1GjRqFL774Qqp9w4YNsLe3R6tWraTaa9euXao5AIAWLVrA1tYWx44dk9qOHz8OpVKJ6OhopKamAnj+F/ypU6e05mfDhg0IDAxEjRo1sGjRIsyYMQPXrl1D586dtYLX1atX0bFjR8TExOCjjz7C0qVLYWlpiQEDBmDHjh0AAF9fX0ycOBEA8PHHH0vb5OnpWept+reSrPvf3n33XURHR2PWrFkICQnBzz//jAkTJmj1mTZtGmbPno127dphyZIl8PDwQEBAAJ48eSL1Kcn23Lx5E6+99hp69uyJpUuXombNmhg1apRWWAwLC8Ps2bPRrVs3fPnll/jkk0/g6uqKCxculGleqJoQRNXc2rVrBQBx9uzZQvvY2NiI1q1bS+9nzZol/v3H5/PPPxcAxN9//13oZ5w9e1YAEGvXrs23rGvXrgKAWLNmTYHLunbtKr0/cuSIACDq1KkjUlNTpfbt27cLAOKLL76Q2tzc3MTIkSOL/cyiahs5cqRwc3OT3u/cuVMAEPPmzdPq99prrwmFQiFu3rwptQEQpqamWm3R0dECgFixYkW+df1beHi4ACA2btwotT179kz4+PiIGjVqaG27m5ubCAwMLPLzXvT3338LAGLWrFlSW2BgoGjfvr30ftCgQWLQoEHCyMhI7Nu3TwghxIULFwQAsWvXLiGEEGlpacLW1laMHTtW6/MTExOFjY2NVnuPHj1Ey5YtxdOnT6U2jUYjXn75ZeHh4SG1ff/99wKAOHLkSIm2JW9/LGr/K+m68/48+Pv7C41GI7VPnjxZGBkZicePH0vbZ2xsLAYMGKC1nrCwMAFAa78ranvc3NwEAHHs2DGpLTk5WZiZmYn3339favP29i71z5goD4/sEJVAjRo1irwqy9bWFgCwa9cunU/mNTMzw+jRo0vc/80334SVlZX0/rXXXoOzszP27t2r0/pLau/evTAyMpL+tZ7n/fffhxAC+/bt02r39/dHw4YNpfdeXl6wtrbGn3/+Wex6nJyc8Prrr0ttJiYmmDhxItLT03H06FE9bI22Ll264MKFC9KRiRMnTqBv375o1aoVjh8/DuD50R6FQoHOnTsDeP715ePHj/H6669DrVZLLyMjI3To0AFHjhwBADx69AiHDx/GkCFDkJaWJvV7+PAhAgICEBcXh7/++kvv26TruseNG6f1VW2XLl2Qm5uLO3fuAAAOHTqEnJwcvPPOO1rj3n333VLX16xZM3Tp0kV6X7t2bTRp0kRrH7G1tcXVq1cRFxdX6s8nYtghKoH09HStYPGioUOHolOnThgzZgwcHR0xbNgwbN++vVTBp06dOqU6GdnDw0PrvUKhQKNGjcr98t47d+7AxcUl33zkfS2R95dhHldX13yfUbNmTfzzzz/FrsfDwwNKpfavqcLWow9dunRBTk4OTp8+jdjYWCQnJ6NLly7w9fXVCjvNmjWDnZ0dAEh/+Xbv3h21a9fWeh04cADJyckAnn9VI4TAjBkz8vXLu4osr6++6bLuF39uNWvWBADp55Y3//++wg0A7OzspL4lVZJ9ZM6cOXj8+DEaN26Mli1bYsqUKbh8+XKp1kPVF6/GIirGvXv3kJKSku+X+r+pVCocO3YMR44cwS+//IL9+/dj27Zt6N69Ow4cOAAjI6Ni15N3pZc+FXbjw9zc3BLVpA+FrUe8cDJzZdCuXTuYm5vj2LFjcHV1hYODAxo3bowuXbpg1apVyMrKwvHjxzFw4EBpTF6g3bBhA5ycnPJ9Zt5Ve3n9PvjgAwQEBBS4/qL2sbLQZd0V+XMrybp8fX1x69Yt7Nq1CwcOHMC3336Lzz//HGvWrMGYMWP0XhPJC8MOUTE2bNgAAIX+JZFHqVSiR48e6NGjB5YtW4YFCxbgk08+wZEjR+Dv76/3Oy6/eDhfCIGbN29qXV5ds2ZNPH78ON/YO3fuoEGDBtL70tTm5uaGgwcPIi0tTevozvXr16Xl+uDm5obLly9Do9FoHd3R93r+zdTUFO3bt8fx48fh6uoqfbXSpUsXZGVlYdOmTUhKStI6OTnvKzoHBwf4+/sX+tl5821iYlJkP6B0P4+SKM26Sypv/m/evAl3d3ep/eHDh/mO2ulre+zs7DB69GiMHj0a6enp8PX1RVhYGMMOFYtfYxEV4fDhw5g7dy7c3d0xYsSIQvs9evQoX1vezfmysrIAAJaWlgBQYPjQxfr167XOI/rhhx/w4MED9OnTR2pr2LAhfvvtNzx79kxq27NnT75L1EtTW9++fZGbm4svv/xSq/3zzz+HQqHQWn9Z9O3bF4mJidi2bZvUlpOTgxUrVqBGjRro2rWrXtbzoi5duuDMmTM4cuSIFHbs7e3h6emJRYsWSX3yBAQEwNraGgsWLEB2dna+z8u7XNvBwQF+fn746quv8ODBg0L7AfrfV0qz7pLq0aMHjI2NsXr1aq32F/cLQD/b8+LVezVq1ECjRo2kP19EReGRHaL/s2/fPly/fh05OTlISkrC4cOHERkZCTc3N+zevRvm5uaFjp0zZw6OHTuGwMBAuLm5ITk5GatWrULdunWlE1kbNmwIW1tbrFmzBlZWVrC0tESHDh20/lVcGnZ2dujcuTNGjx6NpKQkhIeHo1GjRhg7dqzUZ8yYMfjhhx/Qu3dvDBkyBLdu3cLGjRu1ThgubW2vvPIKunXrhk8++QS3b9+Gt7c3Dhw4gF27dmHSpEn5PltX48aNw1dffYVRo0bh/PnzqF+/Pn744QecPHkS4eHhRZ5DVRZdunTB/PnzcffuXa1Q4+vri6+++gr169dH3bp1pXZra2usXr0ab7zxBtq0aYNhw4ahdu3aSEhIwC+//IJOnTpJAWDlypXo3LkzWrZsibFjx6JBgwZISkrC6dOnce/ePURHRwN4HpSNjIywaNEipKSkwMzMDN27d4eDg0ORtS9btgwWFhZabUqlEh9//HGJ111Sjo6OeO+996TbLPTu3RvR0dHYt28f7O3ttY7m6Lo9/9asWTP4+fmhbdu2sLOzw7lz5/DDDz/kuxyeqEAGvBKMqFLIu9Q272VqaiqcnJxEz549xRdffKF1iXOeFy89P3TokOjfv79wcXERpqamwsXFRbz++uvixo0bWuN27dolmjVrJoyNjbUu9e7atato3rx5gfUVdun5li1bxLRp04SDg4NQqVQiMDBQ3LlzJ9/4pUuXijp16ggzMzPRqVMnce7cuXyfWVRtL156LsTzy60nT54sXFxchImJifDw8BBLlizRulRZiOeXno8fPz5fTYVdEv+ipKQkMXr0aGFvby9MTU1Fy5YtC7w8Xl+XngshRGpqqjAyMhJWVlYiJydHat+4caMAIN54440CP+/IkSMiICBA2NjYCHNzc9GwYUMxatQoce7cOa1+t27dEm+++aZwcnISJiYmok6dOqJfv37ihx9+0Or3zTffiAYNGggjI6NiL0PP2x8LehkZGZVq3YXdiiFvv/t3HTk5OWLGjBnCyclJqFQq0b17dxETEyNq1aol3n777RJtT2E/uxf30Xnz5on27dsLW1tboVKpRNOmTcX8+fPFs2fPCp0XojwKISrhWYJERFQlPX78GDVr1sS8efPwySefGLocIgA8Z4eIiHRU0N26w8PDAaBSPD2eKA/P2SEiIp1s27YNERER6Nu3L2rUqIETJ05gy5Yt6NWrFzp16mTo8ogkDDtERKQTLy8vGBsbY/HixUhNTZVOWp43b56hSyPSwnN2iIiISNZ4zg4RERHJGsMOERERyRrP2cHz58bcv38fVlZWer9NOxEREZUPIQTS0tLg4uKS76HB/8awA+D+/fuoV6+eocsgIiIiHdy9e1frzuYvYtgBpNvO3717F9bW1vmWZ2dn48CBA+jVqxdMTEwqurxKj/NTPM5R8ThHxeMcFY3zUzy5zVFqairq1atX7ONjGHbw/5/Ia21tXWjYsbCwgLW1tSx2Dn3j/BSPc1Q8zlHxOEdF4/wUT65zVNwpKDxBmYiIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkzdjQBRBVZQkJCVCr1cX202g0AIDo6Ggolc//jWFvbw9XV9dyrY+IiBh2iHSWkJCApp6eyMzIKLavSqXCli1b4Ovri8zMzOdtFha4HhPDwENEVM4Ydoh0pFarkZmRgSHzVsPB3aPIvkYQAJ5g3Le7kQsFkuPjsH16CNRqNcMOEVE5Y9ghKiMHdw/U8fQuso9SkwPcOwOXJi2gUfKPHRFRReIJykRERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrvG89VXslfXL5i2JiYsqhGiIi0jeGHarWSvPkciIiqpoYdqhaK82Ty18Ue/IQIlctLKfKiIhIXxh2iFCyJ5e/KDk+rpyqISIifeIJykRERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQka7wai8iAynJjQnt7e7i6uuqxGiIieWLYITKANHUSFEolgoKCdP4MlYUFrsfEMPAQERWDYYfIADLTUiE0Gp1uZgg8v8fP9ukhUKvVDDtERMVg2CEyIF1uZkhERKXDE5SJiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWDBp2cnNzMWPGDLi7u0OlUqFhw4aYO3cuhBBSHyEEZs6cCWdnZ6hUKvj7+yMuLk7rcx49eoQRI0bA2toatra2CA4ORnp6ekVvDhEREVVCxoZc+aJFi7B69WqsW7cOzZs3x7lz5zB69GjY2Nhg4sSJAIDFixdj+fLlWLduHdzd3TFjxgwEBATg2rVrMDc3BwCMGDECDx48QGRkJLKzszF69GiMGzcOmzdvNuTmEZW7mJgYncbZ29vD1dVVz9UQEVVOBg07p06dQv/+/REYGAgAqF+/PrZs2YLff/8dwPOjOuHh4Zg+fTr69+8PAFi/fj0cHR2xc+dODBs2DDExMdi/fz/Onj2Ldu3aAQBWrFiBvn374rPPPoOLi4thNo6oHKWpk6BQKhEUFKTTeJWFBa7HxDDwEFG1YNCw8/LLL+Prr7/GjRs30LhxY0RHR+PEiRNYtmwZACA+Ph6JiYnw9/eXxtjY2KBDhw44ffo0hg0bhtOnT8PW1lYKOgDg7+8PpVKJM2fOYODAgRW+XUTlLTMtFUKjwZB5q+Hg7lGqscnxcdg+PQRqtZphh4iqBYOGnY8++gipqalo2rQpjIyMkJubi/nz52PEiBEAgMTERACAo6Oj1jhHR0dpWWJiIhwcHLSWGxsbw87OTurzoqysLGRlZUnvU1NTAQDZ2dnIzs7O1z+vraBlVLXnR6PRQKVSwQgCSk1OqcYaKxUlHpu3PO+/pRlb1Lqd3RvBpUnzUo01goBKpYJGo6lUP7OqvB9VFM5R0Tg/xZPbHJV0OxTi32cDV7CtW7diypQpWLJkCZo3b45Lly5h0qRJWLZsGUaOHIlTp06hU6dOuH//PpydnaVxQ4YMgUKhwLZt27BgwQKsW7cOsbGxWp/t4OCA2bNnIyQkJN96w8LCMHv27HztmzdvhoWFhf43lIiIiPQuIyMDw4cPR0pKCqytrQvtZ9AjO1OmTMFHH32EYcOGAQBatmyJO3fuYOHChRg5ciScnJwAAElJSVphJykpCa1atQIAODk5ITk5Wetzc3Jy8OjRI2n8i6ZNm4bQ0FDpfWpqKurVq4devXoVOFnZ2dmIjIxEz549YWJiUqZtlqOqPD/R0dHw9fXFuG93w6VJi9KNPbALO+ZOLtFYpSYHHvfPI86lLTRK41KNLeu6X3Q/9gq+HvMqjh07Bm9v71Kvu7xU5f2oonCOisb5KZ7c5ijvm5niGDTsZGRkQKnUvvrdyMgIGo0GAODu7g4nJyccOnRICjepqak4c+aMdMTGx8cHjx8/xvnz59G2bVsAwOHDh6HRaNChQ4cC12tmZgYzM7N87SYmJkX+8ItbXt1VxflRKpXIzMxELhTQKEv3xyFHI0o9VqM0hkZprNPYsq47Ty4UyMzMhFKprJQ/r6q4H1U0zlHROD/Fk8sclXQbDBp2XnnlFcyfPx+urq5o3rw5Ll68iGXLluGtt94CACgUCkyaNAnz5s2Dh4eHdOm5i4sLBgwYAADw9PRE7969MXbsWKxZswbZ2dmYMGEChg0bxiuxiIiIyLBhZ8WKFZgxYwbeeecdJCcnw8XFBf/9738xc+ZMqc+HH36IJ0+eYNy4cXj8+DE6d+6M/fv3S/fYAYBNmzZhwoQJ6NGjB5RKJQYPHozly5cbYpOIiIiokjFo2LGyskJ4eDjCw8ML7aNQKDBnzhzMmTOn0D52dna8gSAREREViM/GIiIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZMzZ0AUT6kJCQALVaXepxMTEx5VANERFVJgw7VOUlJCSgqacnMjMyDF0KERFVQgw7VOWp1WpkZmRgyLzVcHD3KNXY2JOHELlqYTlVRkRElQHDDsmGg7sH6nh6l2pMcnxcOVVDRESVBU9QJiIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZMzZ0AURkGDExMTqNs7e3h6urq56rISIqPww7RNVMmjoJCqUSQUFBOo1XWVjgekwMAw8RVRkMO0TVTGZaKoRGgyHzVsPB3aNUY5Pj47B9egjUajXDDhFVGQw7RNWUg7sH6nh6G7oMIqJyxxOUiYiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1gwedv766y8EBQWhVq1aUKlUaNmyJc6dOyctF0Jg5syZcHZ2hkqlgr+/P+Li4rQ+49GjRxgxYgSsra1ha2uL4OBgpKenV/SmEBERUSVk0LDzzz//oFOnTjAxMcG+fftw7do1LF26FDVr1pT6LF68GMuXL8eaNWtw5swZWFpaIiAgAE+fPpX6jBgxAlevXkVkZCT27NmDY8eOYdy4cYbYJCIiIqpkjA258kWLFqFevXpYu3at1Obu7i79vxAC4eHhmD59Ovr37w8AWL9+PRwdHbFz504MGzYMMTEx2L9/P86ePYt27doBAFasWIG+ffvis88+g4uLS8VuFBEREVUqBg07u3fvRkBAAP7zn//g6NGjqFOnDt555x2MHTsWABAfH4/ExET4+/tLY2xsbNChQwecPn0aw4YNw+nTp2FraysFHQDw9/eHUqnEmTNnMHDgwHzrzcrKQlZWlvQ+NTUVAJCdnY3s7Ox8/fPaClpGhp8fjUYDlUoFIwgoNTmlGmusVFTI2Lzlef8ty3orsu4XGUFApVJBo9Ho/edt6P2oKuAcFY3zUzy5zVFJt0MhhBDlXEuhzM3NAQChoaH4z3/+g7Nnz+K9997DmjVrMHLkSJw6dQqdOnXC/fv34ezsLI0bMmQIFAoFtm3bhgULFmDdunWIjY3V+mwHBwfMnj0bISEh+dYbFhaG2bNn52vfvHkzLCws9LyVREREVB4yMjIwfPhwpKSkwNrautB+Bj2yo9Fo0K5dOyxYsAAA0Lp1a1y5ckUKO+Vl2rRpCA0Nld6npqaiXr166NWrV4GTlZ2djcjISPTs2RMmJiblVldVZej5iY6Ohq+vL8Z9uxsuTVqUbuyBXdgxd3K5j1VqcuBx/zziXNpCozQu03orsu4X3Y+9gq/HvIpjx47B29u7VGOLY+j9qCrgHBWN81M8uc1R3jczxTFo2HF2dkazZs202jw9PfHjjz8CAJycnAAASUlJWkd2kpKS0KpVK6lPcnKy1mfk5OTg0aNH0vgXmZmZwczMLF+7iYlJkT/84pZXd4aaH6VSiczMTORCAY2ydLt0jkZU6FiN0hgapXGZ1muIuvPkQoHMzEwolcpy+1nzz1nxOEdF4/wUTy5zVNJtMOjVWJ06dcr39dONGzfg5uYG4PnJyk5OTjh06JC0PDU1FWfOnIGPjw8AwMfHB48fP8b58+elPocPH4ZGo0GHDh0qYCuIiIioMjPokZ3Jkyfj5ZdfxoIFCzBkyBD8/vvv+Prrr/H1118DABQKBSZNmoR58+bBw8MD7u7umDFjBlxcXDBgwAAAz48E9e7dG2PHjsWaNWuQnZ2NCRMmYNiwYbwSi4iIiAwbdl566SXs2LED06ZNw5w5c+Du7o7w8HCMGDFC6vPhhx/iyZMnGDduHB4/fozOnTtj//790snNALBp0yZMmDABPXr0gFKpxODBg7F8+XJDbBIRERFVMgYNOwDQr18/9OvXr9DlCoUCc+bMwZw5cwrtY2dnh82bN5dHeURERFTFGfxxEURERETliWGHiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZE2nsPPnn3/quw4iIiKicqFT2GnUqBG6deuGjRs34unTp/quiYiIiEhvdLrPzoULF7B27VqEhoZiwoQJGDp0KIKDg9G+fXt910dElVBMTIxO4+zt7eHq6qrnaoiIiqZT2GnVqhW++OILLF26FLt370ZERAQ6d+6Mxo0b46233sIbb7yB2rVr67tWIjKwNHUSFEolgoKCdBqvsrDA9ZgYBh4iqlBluoOysbExBg0ahMDAQKxatQrTpk3DBx98gI8//hhDhgzBokWLtJ5WTkRVW2ZaKoRGgyHzVsPB3aNUY5Pj47B9egjUajXDDhFVqDKFnXPnzuF///sftm7dCktLS3zwwQcIDg7GvXv3MHv2bPTv3x+///67vmolokrCwd0DdTy9DV0GEVGJ6BR2li1bhrVr1yI2NhZ9+/bF+vXr0bdvXyiVz893dnd3R0REBOrXr6/PWomIiIhKTaews3r1arz11lsYNWpUoV9TOTg44LvvvitTcURERERlpVPYiYuLK7aPqakpRo4cqcvHExEREemNTvfZWbt2Lb7//vt87d9//z3WrVtX5qKIiIiI9EWnsLNw4ULY29vna3dwcMCCBQvKXBQRERGRvugUdhISEuDu7p6v3c3NDQkJCWUuioiIiEhfdAo7Dg4OuHz5cr726Oho1KpVq8xFEREREemLTmHn9ddfx8SJE3HkyBHk5uYiNzcXhw8fxnvvvYdhw4bpu0YiIiIinel0NdbcuXNx+/Zt9OjRA8bGzz9Co9HgzTff5Dk7REREVKnoFHZMTU2xbds2zJ07F9HR0VCpVGjZsiXc3Nz0XR8RERFRmZTpcRGNGzdG48aN9VULERERkd7pFHZyc3MRERGBQ4cOITk5GRqNRmv54cOH9VIcERERUVnpFHbee+89REREIDAwEC1atIBCodB3XURERER6oVPY2bp1K7Zv346+ffvqux4iIiIivdLp0nNTU1M0atRI37UQERER6Z1OYef999/HF198ASGEvushIiIi0iudvsY6ceIEjhw5gn379qF58+YwMTHRWv7TTz/ppTgiIiKistIp7Nja2mLgwIH6roWIiIhI73QKO2vXrtV3HURERETlQuebCubk5CAqKgq3bt3C8OHDYWVlhfv378Pa2ho1atTQZ41UTSQkJECtVpd6XExMTDlUQ0REcqFT2Llz5w569+6NhIQEZGVloWfPnrCyssKiRYuQlZWFNWvW6LtOkrmEhAQ09fREZkaGoUshIiKZ0fmmgu3atUN0dDRq1aoltQ8cOBBjx47VW3FUfajVamRmZGDIvNVwcPco1djYk4cQuWphOVVGRERVnU5h5/jx4zh16hRMTU212uvXr4+//vpLL4VR9eTg7oE6nt6lGpMcH1dO1RARkRzodJ8djUaD3NzcfO337t2DlZVVmYsiIiIi0hedwk6vXr0QHh4uvVcoFEhPT8esWbP4CAkiIiKqVHT6Gmvp0qUICAhAs2bN8PTpUwwfPhxxcXGwt7fHli1b9F0jERERkc50Cjt169ZFdHQ0tm7disuXLyM9PR3BwcEYMWIEVCqVvmskIiIi0pnO99kxNjZGUFCQPmshIiIi0judws769euLXP7mm2/qVAwRERGRvul8n51/y87ORkZGBkxNTWFhYcGwQ0RERJWGTldj/fPPP1qv9PR0xMbGonPnzjxBmYiIiCoVncJOQTw8PPDpp5/mO+pDREREZEh6CzvA85OW79+/r8+PJCIiIioTnc7Z2b17t9Z7IQQePHiAL7/8Ep06ddJLYURERET6oFPYGTBggNZ7hUKB2rVro3v37li6dKk+6iIiIiLSC53Cjkaj0XcdREREROVCr+fsEBEREVU2Oh3ZCQ0NLXHfZcuW6bIKIiIiIr3QKexcvHgRFy9eRHZ2Npo0aQIAuHHjBoyMjNCmTRupn0Kh0E+VRERERDrSKey88sorsLKywrp161CzZk0Az280OHr0aHTp0gXvv/++XoskIiIi0pVO5+wsXboUCxculIIOANSsWRPz5s3j1VhERERUqegUdlJTU/H333/na//777+RlpZW5qKIiIiI9EWnsDNw4ECMHj0aP/30E+7du4d79+7hxx9/RHBwMAYNGqTvGomIiIh0ptM5O2vWrMEHH3yA4cOHIzs7+/kHGRsjODgYS5Ys0WuBRERERGWhU9ixsLDAqlWrsGTJEty6dQsA0LBhQ1haWuq1OCKSn5iYmALb825WGh0dDaUy/0Fne3t7uLq6lmttRCRPOoWdPA8ePMCDBw/g6+sLlUoFIQQvNyeiAqWpk6BQKhEUFFTgcpVKhS1btsDX1xeZmZn5l1tY4HpMDAMPEZWaTmHn4cOHGDJkCI4cOQKFQoG4uDg0aNAAwcHBqFmzJq/IIqJ8MtNSITQaDJm3Gg7uHvmWG0EAeIJx3+5GLrT/0ZQcH4ft00OgVqsZdoio1HQKO5MnT4aJiQkSEhLg6ekptQ8dOhShoaEMO0RUKAd3D9Tx9M7XrtTkAPfOwKVJC2iUZTroTESkRaffKAcOHMCvv/6KunXrarV7eHjgzp07eimMiIiISB90uvT8yZMnsLCwyNf+6NEjmJmZlbkoIiIiIn3RKex06dIF69evl94rFApoNBosXrwY3bp101txRERERGWl09dYixcvRo8ePXDu3Dk8e/YMH374Ia5evYpHjx7h5MmT+q6RiAhA4ZetF4eXrRNVbzqFnRYtWuDGjRv48ssvYWVlhfT0dAwaNAjjx4+Hs7OzvmskomquuMvWi8PL1omqt1KHnezsbPTu3Rtr1qzBJ598Uh41ERFpKe6y9aLwsnUiKvU5OyYmJrh8+bLeC/n000+hUCgwadIkqe3p06cYP348atWqhRo1amDw4MFISkrSGpeQkIDAwEBYWFjAwcEBU6ZMQU5Ojt7rIyLDy7tsvTSv0oYjIpIfnU5QDgoKwnfffae3Is6ePYuvvvoKXl5eWu2TJ0/Gzz//jO+//x5Hjx7F/fv3tR40mpubi8DAQDx79gynTp3CunXrEBERgZkzZ+qtNiIiIqradDpnJycnB//73/9w8OBBtG3bNt8zsZYtW1biz0pPT8eIESPwzTffYN68eVJ7SkoKvvvuO2zevBndu3cHAKxduxaenp747bff0LFjRxw4cADXrl3DwYMH4ejoiFatWmHu3LmYOnUqwsLCYGpqqsvmERERkYyU6sjOn3/+CY1GgytXrqBNmzawsrLCjRs3cPHiRel16dKlUhUwfvx4BAYGwt/fX6v9/PnzyM7O1mpv2rQpXF1dcfr0aQDA6dOn0bJlSzg6Okp9AgICkJqaiqtXr5aqDiIiIpKnUh3Z8fDwwIMHD3DkyBEAzx8PsXz5cq2wURpbt27FhQsXcPbs2XzLEhMTYWpqCltbW612R0dHJCYmSn1eXHfe+7w+BcnKykJWVpb0PjU1FcDzk6+zs7Pz9c9rK2gZ6Wd+NBoNVCoVjCCePzagFIyViko/Nm953n/Lst6KrLsix744R/parxEEVCoVNBpNlf8zzN9FReP8FE9uc1TS7VAIIURJP1SpVCIxMREODg4AAGtra1y6dAkNGjQodYF3795Fu3btEBkZKZ2r4+fnh1atWiE8PBybN2/G6NGjtUIJALRv3x7dunXDokWLMG7cONy5cwe//vqrtDwjIwOWlpbYu3cv+vTpU+C6w8LCMHv27HztmzdvLvDO0ERERFT5ZGRkYPjw4UhJSYG1tXWh/cr0tL1S5KR8zp8/j+TkZLRp00Zqy83NxbFjx/Dll1/i119/xbNnz/D48WOtoztJSUlwcnICADg5OeH333/X+ty8q7Xy+hRk2rRpCA0Nld6npqaiXr166NWrV4GTlZ2djcjISPTs2RMmJiY6ba+c6WN+oqOj4evri3Hf7oZLkxalG3tgF3bMnVypxyo1OfC4fx5xLm2hURqXab0VWXdFjn1xjvS13vuxV/D1mFdx7NgxeHvnfwBpVcLfRUXj/BRPbnOU981McUoVdhQKBRQKRb42XfTo0QN//PGHVtvo0aPRtGlTTJ06FfXq1YOJiQkOHTqEwYMHAwBiY2ORkJAAHx8fAICPjw/mz5+P5ORk6WhTZGQkrK2t0axZs0LXbWZmVuAzvExMTIr84Re3vLory/wolUpkZmYiF4pSP/E6RyOqzFiN0hgapXGZ1muIuitybN4c6Wu9uVAgMzMTSqVSNn9++buoaJyf4slljkq6DaX6rSGEwKhRo6Sg8PTpU7z99tv5rsb66aefiv0sKysrtGih/S80S0tL1KpVS2oPDg5GaGgo7OzsYG1tjXfffRc+Pj7o2LEjAKBXr15o1qwZ3njjDSxevBiJiYmYPn06xo8fzweSEhEREYBShp2RI0dqvdf11u0l9fnnn0OpVGLw4MHIyspCQEAAVq1aJS03MjLCnj17EBISAh8fH1haWmLkyJGYM2dOudZFREREVUepws7atWvLqw4AQFRUlNZ7c3NzrFy5EitXrix0jJubG/bu3VuudREREVHVpdMdlImIiIiqCoYdIiIikjWGHSIiIpK1Mt1nh4hI7hISEqBWq3Uaa29vD1dXVz1XRESlxbBDRFSIhIQENPX0RGZGhk7jVRYWuB4Tw8BDZGAMO0REhVCr1cjMyMCQeavh4O5RqrHJ8XHYPj0EarWaYYfIwBh2iIiK4eDugTqeVftRE0TVGcMO6ZWu5zfExMSUQzVEREQMO6RH9+7dQ/MWLXQ+v4GoPOkSqBnCieSBYYf05uHDhzqf3xB78hAiVy0sp8qoOktTJ0GhVJb7422IqPJi2CG90+X8huT4uHKqhqq7zLRUCI2GIZyoGmPYIaJqgSGcqPriHZSJiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWeAdlyqe0Ty7XaDQAgNjY2PIqiYiISGcMO6QlISEBTT09S/XkcpVKhS1btmDs2LHlWBkREZFuGHZIi1qtLvWTy40gADxBtzHvY++KeeVbIBERUSkx7FCBSvPQRKUmB7h3BrbOdcu5KiIiotJj2CEiKkcxMTE6jbO3t4erq6ueqyGqnhh2iIjKQZo6CQqlEkFBQTqNV1lY4HpMDAMPkR4w7BARlYPMtFQIjaZU57/lSY6Pw/bpIVCr1Qw7RHrAsENEVI5Kc/4bEZUP3lSQiIiIZI1hh4iIiGSNYYeIiIhkjWGHiIiIZI1hh4iIiGSNYYeIiIhkjZeeExFVUi/efVmj0QAAoqOjoVQW/m9V3n2ZSBvDDhFRJVPY3ZdVKhW2bNkCX19fZGZmFjqed18m0sawQ0RUyRR292UjCABPMO7b3ciFosCxvPsyUX4MO0REldSLd19WanKAe2fg0qQFNEr++iYqKZ6gTERERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLJmbOgCiIhI/2JiYnQaZ29vD1dXVz1XQ2RYDDtERDKSpk6CQqlEUFCQTuNVFha4HhPDwEOywrBDRCQjmWmpEBoNhsxbDQd3j1KNTY6Pw/bpIVCr1Qw7JCsMO0REMuTg7oE6nt6GLoOoUuAJykRERCRrDDtEREQkaww7REREJGsMO0RERCRrBg07CxcuxEsvvQQrKys4ODhgwIABiI2N1erz9OlTjB8/HrVq1UKNGjUwePBgJCUlafVJSEhAYGAgLCws4ODggClTpiAnJ6ciN4WIiIgqKYOGnaNHj2L8+PH47bffEBkZiezsbPTq1QtPnjyR+kyePBk///wzvv/+exw9ehT379/HoEGDpOW5ubkIDAzEs2fPcOrUKaxbtw4RERGYOXOmITaJiIiIKhmDXnq+f/9+rfcRERFwcHDA+fPn4evri5SUFHz33XfYvHkzunfvDgBYu3YtPD098dtvv6Fjx444cOAArl27hoMHD8LR0RGtWrXC3LlzMXXqVISFhcHU1NQQm0ZERESVRKW6z05KSgoAwM7ODgBw/vx5ZGdnw9/fX+rTtGlTuLq64vTp0+jYsSNOnz6Nli1bwtHRUeoTEBCAkJAQXL16Fa1bt863nqysLGRlZUnvU1NTAQDZ2dnIzs7O1z+vraBlcqPRaKBSqWAEAaWmZF8F5vUzVipKPTaP3MfmLdfHXFVk3RU59sU5qgo1V/TYouZIH+s1goBKpYJGo6mSv++q0+9qXcltjkq6HQohhCjnWkpEo9Hg1VdfxePHj3HixAkAwObNmzF69GitYAIA7du3R7du3bBo0SKMGzcOd+7cwa+//iotz8jIgKWlJfbu3Ys+ffrkW1dYWBhmz56dr33z5s2wsLDQ85YRERFRecjIyMDw4cORkpICa2vrQvtVmiM748ePx5UrV6SgU56mTZuG0NBQ6X1qairq1auHXr16FThZ2dnZiIyMRM+ePWFiYlLu9RlSdHQ0fH19Me7b3XBp0qJEY5SaHHjcP4+frifh+9mTSjVWWu+BXdgxd7Jsx+bNUZxLW2iUxmVab0XWXZFjX5yjqlBzRY8tao70sd77sVfw9ZhXcezYMXh7V727L1en39W6ktsc5X0zU5xKEXYmTJiAPXv24NixY6hbt67U7uTkhGfPnuHx48ewtbWV2pOSkuDk5CT1+f3337U+L+9qrbw+LzIzM4OZmVm+dhMTkyJ/+MUtlwOlUonMzEzkQlHoL9PC5GgExxZDozSGRmlcpvUaou6KHJs3R1Wp5ooeW9Ac6WO9uVAgMzMTSqWySv+uqw6/q8tKLnNU0m0w6NVYQghMmDABO3bswOHDh+Hu7q61vG3btjAxMcGhQ4ekttjYWCQkJMDHxwcA4OPjgz/++APJyclSn8jISFhbW6NZs2YVsyFERERUaRn0yM748eOxefNm7Nq1C1ZWVkhMTAQA2NjYQKVSwcbGBsHBwQgNDYWdnR2sra3x7rvvwsfHBx07dgQA9OrVC82aNcMbb7yBxYsXIzExEdOnT8f48eMLPHpDRERE1YtBw87q1asBAH5+flrta9euxahRowAAn3/+OZRKJQYPHoysrCwEBARg1apVUl8jIyPs2bMHISEh8PHxgaWlJUaOHIk5c+ZU1GYQERFRJWbQsFOSC8HMzc2xcuVKrFy5stA+bm5u2Lt3rz5LIyIiIpngs7GIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWDPogUCIiqnxiYmJ0Gmdvbw9XV1c9V0NUdgw7REQEAEhTJ0GhVCIoKEin8SoLC1yPiWHgoUqHYYeIiAAAmWmpEBoNhsxbDQd3j1KNTY6Pw/bpIVCr1Qw7VOkw7BARkRYHdw/U8fQ2dBlEesMTlImIiEjWGHaIiIhI1hh2iIiISNYYdoiIiEjWGHaIiIhI1hh2iIiISNZ46blMJSQkQK1Wl3qcrndOJSIiqqwYdmQoISEBTT09kZmRYehSiIiIDI5hR4bUajUyMzJ0ugtq7MlDiFy1sJwqIyIiqngMOzKmy11Qk+PjyqkaIiIiw+AJykRERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrDDtEREQkaww7REREJGsMO0RERCRrfFwEERHpTUxMjE7j7O3t4erqqudqiJ5j2CEiojJLUydBoVQiKChIp/EqCwtcj4lh4KFywbBDRERllpmWCqHRYMi81XBw9yjV2OT4OGyfHgK1Ws2wQ+WCYYeIiPTGwd0DdTy9DV0GkRaeoExERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxrBDREREssawQ0RERLLGsENERESyxqeel7OEhASo1Wqdxtrb28PV1VXPFRERVU4xMTE6jePvSioOw045SkhIQFNPT2RmZOg0XmVhgesxMfxDTESylqZOgkKpRFBQkE7j835XOjs767kykguGnXKkVquRmZGBIfNWw8Hdo1Rjk+PjsH16CI4fPw5PT89SjdX1X0dERIaQmZYKodGU6XelWq1m2KFCMexUAAd3D9Tx9C7VmLL+S4eIqKrR5XclUUkw7FRSZfmXTuzJQ4hctbCcKiMiIqpaGHYqOV3+pZMcH1dO1RAREVU9vPSciIiIZI1hh4iIiGSNYYeIiIhkjefsEBFRlRcTEwONRgMAiI6OhlJZsn/L84aE1QPDDhERVVn/vk2HSqXCli1b4Ovri8zMzBKN581bqweGHSIiqrL+fZsOZ/dGAJ5g3Le7kQtFsWP/fUNChh15k03YWblyJZYsWYLExER4e3tjxYoVaN++vaHLIiKiCuDg7gGXJs2Be2fg0qQFNMqS//XGZ3LJnyzCzrZt2xAaGoo1a9agQ4cOCA8PR0BAAGJjY+Hg4GDo8oiIqBLS1zO5GHgqP1mEnWXLlmHs2LEYPXo0AGDNmjX45Zdf8L///Q8fffSRgasjIqLKSF/P5GLYqfyqfNh59uwZzp8/j2nTpkltSqUS/v7+OH36tAErIyKiqqAsz+TS9SuwrKwsmJmZVfjYmjVr6jQOABISEqBWq3Uaa+iv/Kp82FGr1cjNzYWjo6NWu6OjI65fv17gmKysLGRlZUnvU1JSAACPHj1CdnZ2vv7Z2dnIyMjAw4cPYWJiUuLaUlNTYW5ujqTYP5CTkV7icQDwz90/q8xYIwjUs8zE47vxVabmih6bN0cJF39DLhRlWm9F1l2RY1+co6pQc0WPLWqOKmvNFTlWZKQVOz/6Wu/dqxehsrDAmDFjSjUuj0KphPi/S+UrcqyNrS0+X7YMx48fL/Hl+QCQnJyM/779Np6W8Cq3F6lUKkRFRaFOnTo6jS9MWloaAEAIUXRHUcX99ddfAoA4deqUVvuUKVNE+/btCxwza9YsAYAvvvjiiy+++JLB6+7du0VmhSp/ZMfe3h5GRkZISkrSak9KSoKTk1OBY6ZNm4bQ0FDpvUajwaNHj1CrVi0oFPn/NZCamop69erh7t27sLa21u8GyADnp3ico+JxjorHOSoa56d4cpsjIQTS0tLg4uJSZL8qH3ZMTU3Rtm1bHDp0CAMGDADwPLwcOnQIEyZMKHCMmZlZvu87bW1ti12XtbW1LHaO8sL5KR7nqHico+JxjorG+SmenObIxsam2D5VPuwAQGhoKEaOHIl27dqhffv2CA8Px5MnT6Srs4iIiKj6kkXYGTp0KP7++2/MnDkTiYmJaNWqFfbv35/vpGUiIiKqfmQRdgBgwoQJhX5tVVZmZmaYNWuWzpf6yR3np3ico+JxjorHOSoa56d41XWOFEIUd70WERERUdVV8ovsiYiIiKoghh0iIiKSNYYdIiIikjWGHSIiIpI1hp1irFy5EvXr14e5uTk6dOiA33//3dAlVRphYWFQKBRar6ZNmxq6LIM6duwYXnnlFbi4uEChUGDnzp1ay4UQmDlzJpydnaFSqeDv74+4uDjDFGsgxc3RqFGj8u1XvXv3NkyxBrBw4UK89NJLsLKygoODAwYMGIDY2FitPk+fPsX48eNRq1Yt1KhRA4MHD853F3k5K8kc+fn55duP3n77bQNVXLFWr14NLy8v6caBPj4+2Ldvn7S8Ou4/DDtF2LZtG0JDQzFr1ixcuHAB3t7eCAgIQHJysqFLqzSaN2+OBw8eSK8TJ04YuiSDevLkCby9vbFy5coCly9evBjLly/HmjVrcObMGVhaWiIgIABPnz6t4EoNp7g5AoDevXtr7VdbtmypwAoN6+jRoxg/fjx+++03REZGIjs7G7169cKTJ0+kPpMnT8bPP/+M77//HkePHsX9+/cxaNAgA1ZdsUoyRwAwduxYrf1o8eLFBqq4YtWtWxeffvopzp8/j3PnzqF79+7o378/rl69CqCa7j96eRqnTLVv316MHz9eep+bmytcXFzEwoULDVhV5TFr1izh7e1t6DIqLQBix44d0nuNRiOcnJzEkiVLpLbHjx8LMzMzsWXLFgNUaHgvzpEQQowcOVL079/fIPVURsnJyQKAOHr0qBDi+T5jYmIivv/+e6lPTEyMACBOnz5tqDIN6sU5EkKIrl27ivfee89wRVUyNWvWFN9++2213X94ZKcQz549w/nz5+Hv7y+1KZVK+Pv74/Tp0wasrHKJi4uDi4sLGjRogBEjRiAhIcHQJVVa8fHxSExM1NqnbGxs0KFDB+5TL4iKioKDgwOaNGmCkJAQPHz40NAlGUxKSgoAwM7ODgBw/vx5ZGdna+1HTZs2haura7Xdj16cozybNm2Cvb09WrRogWnTpiEjI8MQ5RlUbm4utm7diidPnsDHx6fa7j+yuYOyvqnVauTm5uZ75ISjoyOuX79uoKoqlw4dOiAiIgJNmjTBgwcPMHv2bHTp0gVXrlyBlZWVocurdBITEwGgwH0qbxk9/wpr0KBBcHd3x61bt/Dxxx+jT58+OH36NIyMjAxdXoXSaDSYNGkSOnXqhBYtWgB4vh+Zmprme3hxdd2PCpojABg+fDjc3Nzg4uKCy5cvY+rUqYiNjcVPP/1kwGorzh9//AEfHx88ffoUNWrUwI4dO9CsWTNcunSpWu4/DDuksz59+kj/7+XlhQ4dOsDNzQ3bt29HcHCwASujqmzYsGHS/7ds2RJeXl5o2LAhoqKi0KNHDwNWVvHGjx+PK1euVPtz4YpS2ByNGzdO+v+WLVvC2dkZPXr0wK1bt9CwYcOKLrPCNWnSBJcuXUJKSgp++OEHjBw5EkePHjV0WQbDr7EKYW9vDyMjo3xnqCclJcHJyclAVVVutra2aNy4MW7evGnoUiqlvP2G+1TpNGjQAPb29tVuv5owYQL27NmDI0eOoG7dulK7k5MTnj17hsePH2v1r477UWFzVJAOHToAQLXZj0xNTdGoUSO0bdsWCxcuhLe3N7744otqu/8w7BTC1NQUbdu2xaFDh6Q2jUaDQ4cOwcfHx4CVVV7p6em4desWnJ2dDV1KpeTu7g4nJyetfSo1NRVnzpzhPlWEe/fu4eHDh9VmvxJCYMKECdixYwcOHz4Md3d3reVt27aFiYmJ1n4UGxuLhISEarMfFTdHBbl06RIAVJv96EUajQZZWVnVd/8x9BnSldnWrVuFmZmZiIiIENeuXRPjxo0Ttra2IjEx0dClVQrvv/++iIqKEvHx8eLkyZPC399f2Nvbi+TkZEOXZjBpaWni4sWL4uLFiwKAWLZsmbh48aK4c+eOEEKITz/9VNja2opdu3aJy5cvi/79+wt3d3eRmZlp4MorTlFzlJaWJj744ANx+vRpER8fLw4ePCjatGkjPDw8xNOnTw1deoUICQkRNjY2IioqSjx48EB6ZWRkSH3efvtt4erqKg4fPizOnTsnfHx8hI+PjwGrrljFzdHNmzfFnDlzxLlz50R8fLzYtWuXaNCggfD19TVw5RXjo48+EkePHhXx8fHi8uXL4qOPPhIKhUIcOHBACFE99x+GnWKsWLFCuLq6ClNTU9G+fXvx22+/GbqkSmPo0KHC2dlZmJqaijp16oihQ4eKmzdvGrosgzpy5IgAkO81cuRIIcTzy89nzJghHB0dhZmZmejRo4eIjY01bNEVrKg5ysjIEL169RK1a9cWJiYmws3NTYwdO7Za/QOjoLkBINauXSv1yczMFO+8846oWbOmsLCwEAMHDhQPHjwwXNEVrLg5SkhIEL6+vsLOzk6YmZmJRo0aiSlTpoiUlBTDFl5B3nrrLeHm5iZMTU1F7dq1RY8ePaSgI0T13H8UQghRcceRiIiIiCoWz9khIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYISIiIllj2CEiIiJZY9ghIiIiWWPYIaIKFxUVBYVCke/5PIbi5+eHSZMmlXrcs2fP0KhRI5w6dUr/RZVSabZh2LBhWLp0afkWRFSJMOwQVXEKhaLIV1hYWIXVcvv2bSgUCuk5RJWNvkPWmjVr4O7ujpdfflkvn1dRpk+fjvnz5yMlJcXQpRBVCIYdoiruwYMH0is8PBzW1tZabR988IGhS5QlIQS+/PJLBAcHV+g6c3Jyyvw5LVq0QMOGDbFx40Y9VEVU+THsEFVxTk5O0svGxgYKhQJOTk5QqVSoU6cOrl+/DuD5U4/t7OzQsWNHaezGjRtRr1496f3du3cxZMgQ2Nraws7ODv3798ft27e11vftt9/C09MT5ubmaNq0KVatWiUty3v6dOvWraFQKODn51fi7Thx4gS6dOkClUqFevXqYeLEiXjy5Im0vH79+liwYAHeeustWFlZwdXVFV9//bXWZ5w6dQqtWrWCubk52rVrh507d0pHmm7fvo1u3boBAGrWrAmFQoFRo0ZJYzUaDT788EPY2dnBycmp2CNi58+fx61btxAYGCi1vfbaa5gwYYL0ftKkSVAoFNLP4NmzZ7C0tMTBgwcBAFlZWZg4cSIcHBxgbm6Ozp074+zZs9L4vCNR+/btQ9u2bWFmZoYTJ07gyZMnePPNN1GjRg04OzsX+JXUqlWr4OHhAXNzczg6OuK1117TWv7KK69g69atRW4jkWwY9tFcRKRPa9euFTY2NtL7Nm3aiCVLlgghhLh06ZKws7MTpqamIi0tTQghxJgxY8SIESOEEEI8e/ZMeHp6irfeektcvnxZXLt2TQwfPlw0adJEZGVlCSGE2Lhxo3B2dhY//vij+PPPP8WPP/4o7OzsREREhBBCiN9//10AEAcPHhQPHjwQDx8+LLDOvIeB/vPPP0KI50+ptrS0FJ9//rm4ceOGOHnypGjdurUYNWqUNMbNzU3Y2dmJlStXiri4OLFw4UKhVCrF9evXhRBCpKSkCDs7OxEUFCSuXr0q9u7dKxo3biwAiIsXL4qcnBzx448/CgAiNjZWPHjwQDx+/FgIIUTXrl2FtbW1CAsLEzdu3BDr1q3Tekp0QZYtWyaaNm2q1bZ8+XLRvHlz6X2rVq2Evb29WL16tRBCiBMnTggTExPx5MkTIYQQEydOFC4uLmLv3r3i6tWrYuTIkaJmzZrSvOXNk5eXlzhw4IC4efOmePjwoQgJCRGurq7i4MGD4vLly6Jfv37CyspKvPfee0IIIc6ePSuMjIzE5s2bxe3bt8WFCxfEF198oVXrvn37hKmpabV5mjxVbww7RDLyYtgJDQ0VgYGBQgghwsPDxdChQ4W3t7fYt2+fEEKIRo0aia+//loIIcSGDRtEkyZNhEajkcZnZWUJlUolfv31VyGEEA0bNhSbN2/WWufcuXOFj4+PEEKI+Ph4KVwU5cWwExwcLMaNG6fV5/jx40KpVIrMzEwhxPOwExQUJC3XaDTCwcFBChKrV68WtWrVkvoLIcQ333yjVc+L683TtWtX0blzZ622l156SUydOrXQbXjvvfdE9+7dtdouX74sFAqFSE5OFo8ePRKmpqZi7ty5YujQoUIIIebNmydefvllIYQQ6enpwsTERGzatEka/+zZM+Hi4iIWL16sVe/OnTulPmlpacLU1FRs375danv48KFQqVRS2Pnxxx+FtbW1SE1NLbT+6OhoAUDcvn270D5EcmFsoANKRFQBunbtiu+++w65ubk4evQoevXqBScnJ0RFRcHLyws3b96UvmqKjo7GzZs3YWVlpfUZT58+xa1bt/DkyRPcunULwcHBGDt2rLQ8JycHNjY2ZaozOjoaly9fxqZNm6Q2IQQ0Gg3i4+Ph6ekJAPDy8pKW531dl5ycDACIjY2Fl5cXzM3NpT7t27cvcQ3//mwAcHZ2lj67IJmZmVrrAp6fC2NnZ4ejR4/C1NQUrVu3Rr9+/bBy5UoAwNGjR6X5vnXrFrKzs9GpUydpvImJCdq3b4+YmBitz23Xrp30/7du3cKzZ8/QoUMHqc3Ozg5NmjSR3vfs2RNubm5o0KABevfujd69e2PgwIGwsLCQ+qhUKgBARkZGkfNCJAcMO0Qy5uvri7S0NFy4cAHHjh3DggUL4OTkhE8//RTe3t5wcXGBh4cHACA9PR1t27bVChx5ateujfT0dADAN998o/UXLQAYGRmVqc709HT897//xcSJE/Mtc3V1lf7fxMREa5lCoYBGoynTunX9bHt7e/zxxx/5xvj6+iIqKgpmZmbw8/ODl5cXsrKycOXKFZw6dUqnE8YtLS1L1d/KygoXLlxAVFQUDhw4gJkzZyIsLAxnz56Fra0tAODRo0cAnv9sieSOJygTyZitrS28vLzw5ZdfwsTEBE2bNoWvry8uXryIPXv2oGvXrlLfNm3aIC4uDg4ODmjUqJHWy8bGBo6OjnBxccGff/6Zb3neicmmpqYAgNzc3FLV2aZNG1y7di3f5zZq1Ej6zOI0adIEf/zxB7KysqS2f5/sW5b6CtK6dWtcv34dQgit9q5duyIqKgpRUVHw8/ODUqmEr68vlixZgqysLOlITsOGDWFqaoqTJ09KY7Ozs3H27Fk0a9as0PU2bNgQJiYmOHPmjNT2zz//4MaNG1r9jI2N4e/vj8WLF+Py5cu4ffs2Dh8+LC2/cuUK6tatC3t7+zLNA1FVwLBDJHN+fn7YtGmTFGzs7Ozg6emJbdu2aYWdESNGwN7eHv3798fx48cRHx+PqKgoTJw4Effu3QMAzJ49GwsXLsTy5ctx48YN/PHHH1i7di2WLVsGAHBwcIBKpcL+/fuRlJRU4vu4TJ06FadOncKECRNw6dIlxMXFYdeuXVpXNhVn+PDh0Gg0GDduHGJiYvDrr7/is88+A/D8iAsAuLm5QaFQYM+ePfj777+lo1W66NatG9LT03H16lWtdj8/P1y7dg1Xr15F586dpbZNmzahXbt20lEaS0tLhISEYMqUKdi/fz+uXbuGsWPHIiMjo8jL2WvUqIHg4GBMmTIFhw8fxpUrVzBq1Cgolf//1/mePXuwfPlyXLp0CXfu3MH69euh0Wi0vuo6fvw4evXqpfP2E1UlDDtEMte1a1fk5uZqXQbu5+eXr83CwgLHjh2Dq6srBg0aBE9PTwQHB+Pp06ewtrYGAIwZMwbffvst1q5di5YtW6Jr166IiIiQjuwYGxtj+fLl+Oqrr+Di4oL+/fuXqEYvLy8cPXoUN27cQJcuXdC6dWvMnDkTLi4uJd5Oa2tr/Pzzz7h06RJatWqFTz75BDNnzgQA6dyaOnXqYPbs2fjoo4/g6OhYqjD1olq1amHgwIH5vvZr2bIlbG1t0apVK9SoUQNAwfMNAJ9++ikGDx6MN954A23atMHNmzfx66+/ombNmkWue8mSJejSpQteeeUV+Pv7o3Pnzmjbtq203NbWFj/99BO6d+8OT09PrFmzBlu2bEHz5s0BPD8Pa+fOnVrnXhHJmUK8eAyWiEgmNm3ahNGjRyMlJUU6IVefLl++jJ49e+LWrVtSsKkKVq9ejR07duDAgQOGLoWoQvAEZSKSjfXr16NBgwaoU6cOoqOjMXXqVAwZMqRcgg7w/IjUokWLEB8fj5YtW5bLOsqDiYkJVqxYYegyiCoMj+wQkWwsXrwYq1atQmJiIpydnTFgwADMnz9f65JrIqp+GHaIiIhI1niCMhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERyRrDDhEREckaww4RERHJGsMOERERydr/A/zWbtJPF6kOAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. load dataset, only training split\n",
        "dataset = load_dataset(\n",
        "    \"zeroshot/twitter-financial-news-sentiment\",\n",
        "    split=\"train\",\n",
        ")\n",
        "\n",
        "# 2. understand dataset\n",
        "# print first 5 examples\n",
        "print(dataset[:5])\n",
        "\n",
        "# print the columns of the dataset\n",
        "print(dataset.column_names)\n",
        "\n",
        "# get the number of examples in the dataset\n",
        "dataset_size = dataset.shape\n",
        "print(f\"Dataset size: {dataset_size}\")\n",
        "\n",
        "# compute the tweet lengths (in words, i.e., split by whitespace)\n",
        "# plot them and compute the average tweet length\n",
        "tweets = dataset[\"text\"]\n",
        "tweet_lengths = [len(tweet.split()) for tweet in tweets]\n",
        "average_tweet_length = sum(tweet_lengths) / len(tweet_lengths)\n",
        "print(f\"Average tweet length: {average_tweet_length}\")\n",
        "\n",
        "# plot a histogram of the tweet lengths\n",
        "plt.hist(tweet_lengths, bins=30, color='skyblue', edgecolor='black')\n",
        "plt.xlabel(\"Tweet length (words)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Distribution of Tweet Lengths\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPgQicqNK5H2"
      },
      "source": [
        "Click below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "KpvILDZUK5H2",
        "outputId": "4b0d07de-dc19-411f-958c-6e2975f08972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT', '$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3', '$CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb', '$ESS: BTIG Research cuts to Neutral https://t.co/MCyfTsXc2N', '$FNKO - Funko slides after Piper Jaffray PT cut https://t.co/z37IJmCQzB'], 'label': [0, 0, 0, 0, 0]}\n",
            "['text', 'label']\n",
            "Dataset size: 9543\n",
            "Average tweet length: 12.17835062349366\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Tweet length')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. load dataset, only training split\n",
        "dataset = load_dataset(\n",
        "    \"zeroshot/twitter-financial-news-sentiment\",\n",
        "    split=\"train\",\n",
        ")\n",
        "\n",
        "# 2. understand dataset\n",
        "# print first 5 examples\n",
        "print(dataset[:5])\n",
        "\n",
        "# print the columns of the dataset\n",
        "print(dataset.column_names)\n",
        "\n",
        "# get the number of examples in the dataset\n",
        "dataset_size = len(dataset) ### YOUR CODE HERE ###\n",
        "print(f\"Dataset size: {dataset_size}\")\n",
        "\n",
        "# compute the tweet lengths (in words, i.e., split by whitespace)\n",
        "# plot them and compute the average tweet length\n",
        "tweets = dataset[\"text\"]\n",
        "tweet_lengths = [len(tweet.split()) for tweet in tweets] ### YOUR CODE HERE ###\n",
        "average_tweet_length = sum(tweet_lengths) / len(tweet_lengths) ### YOUR CODE HERE ###\n",
        "print(f\"Average tweet length: {average_tweet_length}\")\n",
        "\n",
        "# plot the tweet lengths\n",
        "plt.hist(tweet_lengths, bins=20) ### YOUR CODE HERE ###\n",
        "plt.xlabel(\"Tweet length\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jmcHf83K5H3"
      },
      "source": [
        "```{toggle}\n",
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Answers Exercise 1.1.: Massaging a Twitter dataset</span></strong>\n",
        ">\n",
        "> 2. The Tweet lenght peaks at 10 tokens, followed by between 10 and 15 tokens. The tweet lenght is almost never larger then 25 tokens. The Average tweet length is 12.17835062349366. This is quite small for tweets.\n",
        "> So if you would train your Twitter bot with this dataset you would receive a bot that answers in very short sentences. If that is what you are looking for, the dataset would be appropiate.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iExn3e-xK5H3",
        "outputId": "aef5aa9d-bb9d-4847-f84a-9b421bc9070a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['BYND  JPMorgan reels in expectations on Beyond Meat httpstcobdxbFGjkT', 'CCL RCL  Nomura points to bookings weakness at Carnival and Royal Caribbean httpstcoyGjpTReD'], 'label': [0, 0]}\n"
          ]
        }
      ],
      "source": [
        "# 4. clean tweets: remove non-alphabetic or non-space characters\n",
        "# Hint: you can easily google how to remove non-alphabetic characters in Python\n",
        "\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Remove non-alphabetic or non-space characters from a tweet.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    tweet: str\n",
        "        Tweet to clean.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cleaned_tweet: str\n",
        "        Cleaned tweet without non-alphabetic symbols.\n",
        "    \"\"\"\n",
        "    tweet = \"\".join(\n",
        "        [char for char in tweet if char.isalpha() or char.isspace()]\n",
        "    )\n",
        "    return tweet\n",
        "\n",
        "# apply the preprocessing function to all tweets\n",
        "cleaned_dataset = dataset.map(\n",
        "    lambda example: {\n",
        "        \"text\": clean_tweet(example[\"text\"])\n",
        "    }\n",
        ")\n",
        "\n",
        "# look at a few examples of clean tweets\n",
        "print(cleaned_dataset[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCX335EqK5H3"
      },
      "source": [
        "Click below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "mafa0KrSK5H4",
        "outputId": "a73573a8-1f7d-4a2a-d3e3-71217cfd4d9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['BYND  JPMorgan reels in expectations on Beyond Meat httpstcobdxbFGjkT'], 'label': [0]}\n"
          ]
        }
      ],
      "source": [
        "# 4. clean tweets: remove non-alphabetic characters\n",
        "# Hint: you can easily google how to remove non-alphabetic characters in Python\n",
        "\n",
        "\n",
        "def clean_tweet(tweet):\n",
        "    \"\"\"\n",
        "    Remove non-alphabetic or non-space characters from a tweet.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    tweet: str\n",
        "        Tweet to clean.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cleaned_tweet: str\n",
        "        Cleaned tweet without non-alphabetic symbols.\n",
        "    \"\"\"\n",
        "    tweet = \"\".join(\n",
        "        [char for char in tweet if char.isalpha() or char.isspace()]\n",
        "    )  ### YOUR CODE HERE ###\n",
        "    return tweet\n",
        "\n",
        "# apply the preprocessing function to all tweets\n",
        "cleaned_dataset = dataset.map(\n",
        "    lambda example: {\n",
        "        \"text\": clean_tweet(example[\"text\"])\n",
        "    }\n",
        ")\n",
        "\n",
        "# look at a few examples of clean tweets\n",
        "print(cleaned_dataset[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tqv_xgUeK5H4",
        "outputId": "9285b9ac-97d7-43f3-bcf2-b5bb0abd57fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 7634, Test size: 1908\n",
            "Train split examples:  {'text': ['Is ATT Inc NYSET Creating Value For Shareholders', 'Adtalem Global Education  NIPA American University of the Caribbean School of Medicine a httpstcooWxulWEKM', 'Amneal Pharma price target raised to  vs  at SunTrust Robinson Humphrey'], 'label': [2, 2, 1]}\n",
            "Test split examples:  {'text': ['MKD  Molecular Data Starts US IPO Process Subscribe to Seeking Alpha for more httpstcoOncFkzN economy trading business', ' Reasons OrganiGram Should Bounce Back Big Time in ', 'Deluxe delivered record FY revenue'], 'label': [2, 2, 1]}\n"
          ]
        }
      ],
      "source": [
        "# 5. split dataset into training and testing set\n",
        "\n",
        "# select the proportion of the dataset that should be used for training\n",
        "# and the proportion that should be used for testing\n",
        "# commonly train : test is around 80:20\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = int(0.2 * dataset_size)\n",
        "\n",
        "print(f\"Train size: {train_size}, Test size: {test_size}\")\n",
        "\n",
        "# split the dataset into training and testing set\n",
        "# this will create two new sub-datasets with the keys \"train\" and \"test\"\n",
        "cleaned_dataset_split = cleaned_dataset.train_test_split(\n",
        "    test_size=test_size,\n",
        ")\n",
        "\n",
        "print(\"Train split examples: \", cleaned_dataset_split[\"train\"][:3])\n",
        "print(\"Test split examples: \", cleaned_dataset_split[\"test\"][:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v7-Iu-UK5H4"
      },
      "source": [
        "Click below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "ByxAtHMAK5H4",
        "outputId": "92c378b9-f156-4aad-f917-8481b530d6fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 7634, Test size: 1909\n",
            "Train split examples:  {'text': ['Liquefied Natural Gas  Magnolia LNG EPC Contract Extended LiquefiedNaturalGas Stock MarketScreener httpstcocRMBIlK', 'Why Passive Investing Might Be Distorting The Market Podcast', 'Ghana Charges ExFinance Minister After Collapse of Bank'], 'label': [1, 2, 2]}\n",
            "Test split examples:  {'text': ['The second pensionrelated UK university strike in two years will affect more than a million students httpstcoqqlbQeKZK', 'Morgan Stanley says forecasting just the next two months let alone  is hard right now httpstcofToNSUFXu', 'EBay Sells StubHub For B'], 'label': [2, 2, 2]}\n"
          ]
        }
      ],
      "source": [
        "# 5. split dataset into training and testing set\n",
        "\n",
        "# select the proportion of the dataset that should be used for training\n",
        "# and the proportion that should be used for testing\n",
        "# commonly train : test is around 80:20\n",
        "train_size = int(0.8 * dataset_size)  ### YOUR CODE HERE ###\n",
        "test_size = dataset_size - train_size  ### YOUR CODE HERE ###\n",
        "\n",
        "print(f\"Train size: {train_size}, Test size: {test_size}\")\n",
        "\n",
        "# split the dataset into training and testing set\n",
        "# this will create two new sub-datasets with the keys \"train\" and \"test\"\n",
        "cleaned_dataset_split = cleaned_dataset.train_test_split(\n",
        "    test_size=test_size,\n",
        ")\n",
        "\n",
        "print(\"Train split examples: \", cleaned_dataset_split[\"train\"][:3])\n",
        "print(\"Test split examples: \", cleaned_dataset_split[\"test\"][:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DOWDsogOK5H4",
        "outputId": "de72ea93-707e-4c40-87d0-4528cf0d224d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "4d21f0107806477d828d1a08a844feeb",
            "63e2ffbf30a24f2498494de915f7696f",
            "0f3eb6e3124c4e2fb9f7c80a98f98a12",
            "b8890621a5c8452f950ced125c1cb7be",
            "c572dd57a5054685b1a6cbc77053b349",
            "c129cddff14344738cebee25bb143a4f",
            "7caa8aaabe044e05a11f209140005307",
            "e9d8849a80a941cabab0ca42c3e2a21a",
            "5bc40f3cb913469684d145cc684cebab",
            "671f50eb49744623bda3d539da4e06af",
            "7a3e5e34185d4abfb7d0487ab48e72e5"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7634 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d21f0107806477d828d1a08a844feeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# 7-8. Tokenize and batch the dataset with wrappers provided by the datasets package\n",
        "# for tokeinization, we use the GPT-2 tokenizer (more details for what is going on\n",
        "# under the hood of these wrappers is to come in the next sessions)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "def tokenization(example):\n",
        "    \"\"\"\n",
        "    Wrapper around the tokenizer to tokenize the text of an example.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    example: dict\n",
        "        Example tweet from the dataset. Key \"text\" contains the tweet.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Tokenized tweet with token IDs and an attention mask.\n",
        "    \"\"\"\n",
        "    return tokenizer(example[\"text\"]\n",
        "        )\n",
        "\n",
        "# apply the tokenization function to the train dataset\n",
        "preprocessed_train_dataset = cleaned_dataset_split[\"train\"].map(tokenization, batched=True)\n",
        "\n",
        "# datasets provides a handy method to format the dataset for training models with PyTorch\n",
        "# specifically, it makes sure that dataset samples that are loaded from the\n",
        "# dataset are PyTorch tensors. It also selects columns to be used.\n",
        "preprocessed_train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
        ")\n",
        "\n",
        "preprocessed_train_dataset.format['type']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quivc1i-K5H5"
      },
      "source": [
        "Click below to see the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "hide-cell"
        ],
        "id": "ZzzBdlyJK5H5",
        "outputId": "7d2ae3bc-682c-42e6-980a-eab1690a77e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 7634/7634 [00:00<00:00, 32869.18 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'torch'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7-8. Tokenize and batch the dataset with wrappers provided by the datasets package\n",
        "# for tokeinization, we use the GPT-2 tokenizer (more details for what is going on\n",
        "# under the hood of these wrappers is to come in the next sessions)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "def tokenization(example):\n",
        "    \"\"\"\n",
        "    Wrapper around the tokenizer to tokenize the text of an example.\n",
        "\n",
        "    Args\n",
        "    ----\n",
        "    example: dict\n",
        "        Example tweet from the dataset.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Tokenized tweet with token IDs and an attention mask.\n",
        "    \"\"\"\n",
        "    return tokenizer(example[\"text\"])\n",
        "\n",
        "# apply the tokenization function to the train dataset\n",
        "preprocessed_train_dataset = cleaned_dataset_split[\"train\"].map(tokenization, batched=True)\n",
        "\n",
        "#\n",
        "preprocessed_train_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
        ")\n",
        "preprocessed_train_dataset.format['type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wi8TBTGVK5H5",
        "outputId": "044ee844-3317-4691-d508-cb684379aa5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'label': tensor(1), 'input_ids': tensor([   43,  1557,   891,   798, 12068, 14345,   220, 14872, 22703,   406,\n",
            "        10503,   412,  5662, 17453, 24204, 35515,   891,   798, 35364, 39699,\n",
            "        10500,  5991,  3351,   260,   877,  2638,   301,    66,   420, 29138,\n",
            "         3483,    75,    42]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
            "{'label': tensor(2), 'input_ids': tensor([ 5195, 31652,  7488,   278, 24213,  1355,  4307, 24707,   383,  5991,\n",
            "        16036]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
            "{'label': tensor(2), 'input_ids': tensor([41126,  2271, 44620,  1475,    37, 14149,  4139,  2293,  7778,  7512,\n",
            "          286,  5018]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
            "{'label': tensor(2), 'input_ids': tensor([ 2949,  3999,  3142, 24746,  1042,   290,  3252,   389,   783, 14342,\n",
            "         1863,   351,   262, 26920,   615, 19397,  2638,   301,  1073,    41,\n",
            "           52,  8874,    82,    57,    33,    55]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1])}\n",
            "{'label': tensor(1), 'input_ids': tensor([16371, 30011,  2569,  7994,   220, 28628,  5018, 17399,   346,   324,\n",
            "         6123]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
          ]
        }
      ],
      "source": [
        "# finally, to see what the preprocessed dataset looks like\n",
        "# we iterate over the dataset for a few steps, as we would do in training\n",
        "# note: usually a DataLoader would be used to iterate over the dataset for training\n",
        "# we will cover this in the next sessions\n",
        "\n",
        "for i in range(5):\n",
        "    print(preprocessed_train_dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmIsYew8K5H5"
      },
      "source": [
        "**NOTE**: if you are building your own dataset instead of e.g. loading it via `datasets`, PyTorch provides a class `Dataset` which is easily customizable and essentially allows to explicitly implement functionality that is tucked away in the `datasets` package. Working with it is covered in sheet 2.3 (for next week!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE4iKbXgK5H5"
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.2.: Understanding The Pile</span></strong>\n",
        ">\n",
        "> To make things more specific, consider [The Pile dataset (Gao et al., 2020)](https://arxiv.org/pdf/2101.00027.pdf). Read trough the abstract and section 1 (Introduction), look at Table 1 (if needed, glimpse at other sections describing what the single names stand for), read section 5.2.\n",
        "> The following exercises are meant to foster understanding and critical thinking about training datasets. Please try to answer the following questions to yourself:\n",
        ">\n",
        "> 1. Which language(s) does The Pile mainly consist of? If an LM is trained on The Pile as it is, how would you expect the LM will perform when completing a text in, e.g., Hungarian?\n",
        "> It is %94.5 in English, while multilingual data is not eliminated. It would perform very poorly in Hungarian, if the model is not using methods such as back translation while being trained, or not specifically designed for the language. Still, using the language's dataset would perform better of course, since the meanings usually get lost in translation.\n",
        "> 2. What is the difference between The Pile and Common Crawl? Why was The Pile introduced?\n",
        "> Because Common Crawl has been effective on training, but recent work has shown that dataset diversity leads to better downstream generalization\n",
        "capability. Additionally, large-scale\n",
        "language models have been shown to effectively\n",
        "acquire knowledge in a novel domain with only\n",
        "relatively small amounts of training data from that\n",
        "domain.These results suggest that by mixing together a large number of smaller, high quality, diverse datasets, we can improve the general\n",
        "cross-domain knowledge and downstream generalization capabilities of the model compared to models trained on only a handful of data sources.Through some analyses, it can be said that the Pile is\n",
        "significantly distinct from pure Common Crawl\n",
        "data. Additionally, evaluations show that the\n",
        "existing GPT-2 and GPT-3 models perform poorly\n",
        "on many components of the Pile, and that models\n",
        "trained on the Pile significantly outperform both\n",
        "raw and filtered Common Crawl model.\n",
        "> 3. What does the \"epochs\" column in Table 1 refer to? What is the idea behind it?\n",
        ">Epochs is the number of passes over each constituent dataset during a full epoch over the Pile. The idea behind it: Since The Pile is made up of datasets of very different sizes, some datasets are so small they would barely be seen by the model in one full pass through the full corpus (i.e., one epoch).\n",
        "So, they increase the number of \"sub-epochs\" for small datasets so they get more exposure.\n",
        "This way, small but important datasets (e.g., math papers, medical data) don’t get drowned out by huge ones like Pile-CC.\n",
        "> 4. What kind of data is missing from the mix reported in Table 1? What do you think the effect of adding such data would be on an LM trained with the data?\n",
        "> The Pile lacks data like spoken language, underrepresented languages, social media content, and multimodal sources, and adding these would improve a model’s conversational, multilingual, and informal language understanding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oftTqUAK5H5"
      },
      "source": [
        "Click below to see the solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIKK2aTXK5H5"
      },
      "source": [
        "```{toggle}\n",
        "<strong><span style=&ldquo;color:#D83D2B;&rdquo;>Answers Exercise 1.2.: Understanding The Pile</span></strong>\n",
        ">\n",
        ">1.   The majority of the data is english. Additionally is consists in 14 languages. Nonetheless, the main criteria for multilanguage data was the existence of english data. Therefore Hungarian text completion is probably not possible.\n",
        ">2.  Common crawl consists in a large amount of raw data, which can result in a poor quality. Because it is favourable to uses a mixtures of many diverse datasets of high quality and from different fields, the Pile was introduced. Furthermore common crawl is part if The Pile changed into PIle-CC while using jusText on Web Archive files for extraction to receive a higher quality.\n",
        ">3. Epochs are the number of passes over each constituent dataset during a full epoch over the Pile. Therefore smaller datasets can pass the dataset more often the large datasets resulting in a better diversion.\n",
        ">4. The standard diviation of the document could give inforation whether the dataset has strong outliers. It can give an impression whether the dataset is biased in some way or not.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VjMLQ5DK5H6"
      },
      "source": [
        "### Dataset documentation\n",
        "\n",
        "Although datasets are a crucial part of the NLP pipeline, unfortunately, there are very few or no established practices for *documenting* shared datasets or *reporting* the datasets which are used to traing published models. This results in issues of reproducibility of the training because details about the data are unknown, biases of models due to under- or misrepresentation in the data and other issues. This paper (a completely optional read) provides an overview as well as suggestions for improving the situation in the area of machine learning:\n",
        "\n",
        "[Jo & Gebru (2020). Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning](https://dl.acm.org/doi/pdf/10.1145/3351095.3372829)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "npNLG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
